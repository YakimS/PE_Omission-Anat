{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reset\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.stats\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "import gc\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "from os.path import exists\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne import create_info\n",
    "\n",
    "#import auxiliary ## my code\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "epochs_dir = 'C:\\AnatArzData\\YKM_data\\epochs_and_evoked_allSubs'\n",
    "prepro_name = \"referenced\"\n",
    "import_type = \"5Electorodes_plainEEGLAB\"\n",
    "trial_exclution_str = \"_excOulierTrials-3.5\" #\"_excOulierTrials-2.5\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class AuxFuncs:\n",
    "    def __init__(self, import_path):\n",
    "        ## import epochs data and meta-data\n",
    "        with open(import_path, 'rb') as file:\n",
    "            [allEvents_df, allEpochs_perCond, cfg] = pickle.load(file)\n",
    "\n",
    "        self.allEpochs_perCond = allEpochs_perCond\n",
    "        self.allEvents_df = allEvents_df\n",
    "        self.cfg = cfg\n",
    "        self.info,self.montage = self.get_subject_info()\n",
    "\n",
    "        self.max_freq =cfg['sample_freq']/2 # for tfr\n",
    "        self.times = cfg['times']\n",
    "        self.time0_i = np.where(self.times==0)[0][0]\n",
    "        self.hz_y = np.fft.rfftfreq(len(self.times[self.time0_i:]), 1.0/cfg['sample_freq'])\n",
    "\n",
    "\n",
    "    def get_subject_info(self, example_subject = '32'):\n",
    "        subject_setfile_wake_n = f'{self.cfg[\"set_files_dir\"]}\\s_{example_subject}_wake_night_referenced.set'\n",
    "        output_file_path = f\"{self.cfg['outputs_dir_path'] }/epochs_Wn_s{example_subject}_file\"\n",
    "\n",
    "        if exists(output_file_path):\n",
    "            with open(output_file_path, 'rb') as config_dictionary_file:\n",
    "                epochs_Wn_example_sub = pickle.load(config_dictionary_file)\n",
    "                #print(epochs_Wn_example_sub)\n",
    "        else:\n",
    "            epochs_Wn_example_sub = mne.io.read_epochs_eeglab(subject_setfile_wake_n, events=None, event_id=None,eog=(),verbose=None, uint16_codec=None)\n",
    "            with open(output_file_path, 'wb') as epochs_Wn_s_example_file:\n",
    "                pickle.dump(epochs_Wn_example_sub, epochs_Wn_s_example_file)\n",
    "\n",
    "        montage = mne.channels.make_standard_montage('GSN-HydroCel-128')\n",
    "        epochs_Wn_example_sub_piked = epochs_Wn_example_sub.pick_channels(self.cfg['ch_names'])\n",
    "        epochs_Wn_example_sub_monatged = epochs_Wn_example_sub_piked.set_montage(montage)\n",
    "        epochs_info = epochs_Wn_example_sub_monatged.info\n",
    "        return epochs_info, epochs_Wn_example_sub_monatged\n",
    "\n",
    "    def getEpochsPerCond(self,cond_df,dataset):\n",
    "        df_minTrials = cond_df[(cond_df.SamplesCount > 0)] # discard cond with 0 enough samples\n",
    "        keys = (str(key) for key in df_minTrials.Cond_id)\n",
    "        epochs_allSamples = {str_key: dataset[str_key] for str_key in keys}\n",
    "        return df_minTrials, epochs_allSamples\n",
    "\n",
    "    # output: [#conds, #elect, #times]\n",
    "    def getEvokedPerCondAndElectd(self, constraints,dataset, y_ax,outputType='array', tmin=-0.1, baseline=(None, 0)):\n",
    "        curr_df = self.allEvents_df.copy()\n",
    "        # apply constraints\n",
    "        for key in constraints: curr_df = curr_df[(curr_df[key] == constraints[key])]\n",
    "\n",
    "        conds_df, epochsPerCond = self.getEpochsPerCond(curr_df,dataset)\n",
    "        evoked_perCond_andElectd = np.zeros((len(epochsPerCond),np.size(self.cfg['electrodes']),np.size(y_ax)))\n",
    "\n",
    "        for cond_i, cond in enumerate(epochsPerCond):\n",
    "            evoked_perCond_andElectd[cond_i] = np.squeeze(np.nanmean(epochsPerCond[cond], axis=2))\n",
    "\n",
    "        if outputType =='array':\n",
    "            return conds_df, evoked_perCond_andElectd\n",
    "        if outputType =='mne':\n",
    "            mne_epochs = mne.EpochsArray(evoked_perCond_andElectd, self.info, tmin=tmin, baseline=baseline)\n",
    "            return conds_df, mne_epochs\n",
    "\n",
    "import_path = f'{epochs_dir}\\\\{import_type}{trial_exclution_str}.pkl'\n",
    "aux = AuxFuncs(import_path)\n",
    "\n",
    "allEpochs_perCond = aux.allEpochs_perCond\n",
    "allEvents_df = aux.allEvents_df\n",
    "cfg = aux.cfg\n",
    "times = aux.times\n",
    "time0_i = aux.time0_i\n",
    "\n",
    "fig_output_dir = f\"{cfg['outputs_dir_path']}/timefreq_clusterPerm\"\n",
    "if not os.path.exists(fig_output_dir):\n",
    "    os.mkdir(fig_output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def applyDesign(ax,title=''):\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    ax.set_facecolor('silver')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc = 'upper right',prop={'size': 10})\n",
    "    ax.axvline(x=0,color='gray', linestyle='--',label =\"_nolegend_\")\n",
    "    ax.axhline(y=0, color='gray', linestyle='-',label =\"_nolegend_\")\n",
    "    ax.set_ylabel('magnitude')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax.set_xlabel('Time (ms)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time-freq functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cond_1 = {'TOA_cond':'Rand','Vigilance':'N3'}\n",
    "cond_2 = {'TOA_cond':'Fixed','Vigilance':'N3'}\n",
    "contrast_name = \"allSubs_RandvsFixed_N3\"\n",
    "\n",
    "#### Parameters:\n",
    "# ==================\n",
    "# zscore baseline\n",
    "## Tail is 0, so the statistic is thresholded on both sides of the distribution.\n",
    "baseline = (None, 0) ## For timefreq analysis\n",
    "p_value = 0.05 # default 0.05 # for clusters\n",
    "decim = 1# default 2 for testing.. For reals - 1\n",
    "n_permutations=100 # default 1k for testing. For reals - 10K\n",
    "min_freq = 4\n",
    "freqs = np.arange(min_freq,80, 1)  # define frequencies of interest\n",
    "n_cycles = freqs / min_freq # different number of cycle per frequency\n",
    "\n",
    "tail = 0 # 0 = two-tailed test (for clusters (as we want positive and negative clusters))\n",
    "p_value_pixels = 0.05"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def plot_clusters_map(ax1,T_obs,ch_idx,tfr_epochs,t_thresh,T_obs_plot):\n",
    "    vmax = np.max(np.abs(T_obs))\n",
    "    vmin = -vmax\n",
    "    ax1.imshow(T_obs[ch_idx], cmap=plt.cm.gray,\n",
    "               extent=[times[0], times[-1], freqs[0], freqs[-1]],\n",
    "               aspect='auto', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax1.imshow(T_obs_plot[ch_idx], cmap=plt.cm.RdBu_r,\n",
    "               extent=[times[0], times[-1], freqs[0], freqs[-1]],\n",
    "               aspect='auto', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    #ax1.set_colorbar()\n",
    "    ax1.set_xlabel('Time (ms)')\n",
    "    ax1.set_ylabel('Frequency (Hz)')\n",
    "    ax1.set_title(f'Induced power ({tfr_epochs.ch_names[ch_idx]})\\nThreshold:{t_thresh}\\n cluster p_val={p_value}\\ncontrast:{cond_1};{cond_2}')\n",
    "def plot_elecds_erps(ax2,mean_epochs_time_diff,ch_idx,tfr_epochs):\n",
    "    ax2.plot(times,mean_epochs_time_diff.T,color='blue')\n",
    "    mean_electrods = np.nanmean(mean_epochs_time_diff,axis=0)\n",
    "    ax2.plot(times,mean_electrods,color='yellow',label='mean')\n",
    "    ax2.plot(times,mean_epochs_time_diff[ch_idx,:],label=tfr_epochs.ch_names[ch_idx],color='red')\n",
    "    ax2.legend()\n",
    "    ax2.set_xlim(times[0],times[-1])\n",
    "    applyDesign(ax2,'ERP difference')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def stat_fun_wilcox(X):\n",
    "    result = scipy.stats.wilcoxon(X)\n",
    "    return result.statistic\n",
    "\n",
    "def getClustersPerConditions(cond_1,cond_2, contrast_name,apply_baseline_together=True,baseline=(None, 0),cluster_start_time_index=0,test_per_voxel='ttest'):\n",
    "    if test_per_voxel=='ttest':\n",
    "        test_per_voxel = mne.stats.ttest_1samp_no_p\n",
    "    else:\n",
    "        test_per_voxel = stat_fun_wilcox\n",
    "\n",
    "    epochs_time_diff = []\n",
    "    epochs_power_diff = []\n",
    "    for sub in cfg['subs']:\n",
    "        currContr_conds1 = cond_1.copy()\n",
    "        currContr_conds1['Subject'] = sub\n",
    "        __, cont_epochs1 = aux.getEvokedPerCondAndElectd(currContr_conds1,allEpochs_perCond,times, outputType='mne')\n",
    "\n",
    "        if cond_2 == \"baseline\":\n",
    "            baseline_epochs_data = copy.deepcopy(cont_epochs1.get_data())\n",
    "\n",
    "            baseline_orig_data = baseline_epochs_data[:,:,0:time0_i]\n",
    "            baseline_epochs_data[:,:,time0_i:time0_i*2] = baseline_orig_data\n",
    "            baseline_epochs_data[:,:,time0_i*2:time0_i*3] = baseline_orig_data\n",
    "            baseline_epochs_data[:,:,time0_i*3:time0_i*4] = baseline_orig_data\n",
    "            baseline_epochs_data[:,:,time0_i*4:time0_i*5] = baseline_orig_data\n",
    "            baseline_epochs_data[:,:,time0_i*5:] = baseline_orig_data[:,:,:13]\n",
    "\n",
    "            cont_epochs2 = mne.EpochsArray(baseline_epochs_data, aux.info,tmin=-0.1)\n",
    "        else:\n",
    "            currContr_conds2 = cond_2.copy()\n",
    "            currContr_conds2['Subject'] = sub\n",
    "            __, cont_epochs2 = aux.getEvokedPerCondAndElectd(currContr_conds2,allEpochs_perCond,times, outputType='mne')\n",
    "\n",
    "        if apply_baseline_together:\n",
    "            tfr_epochs1 = tfr_morlet(cont_epochs1, freqs, n_cycles=n_cycles, decim=decim, average=False, return_itc=False)\n",
    "            tfr_epochs2 = tfr_morlet(cont_epochs2, freqs, n_cycles=n_cycles, decim=decim, average=False, return_itc=False)\n",
    "\n",
    "            both_tfr_data = np.concatenate((tfr_epochs1.data,tfr_epochs2.data),axis=0)\n",
    "            both_tfr_data_tfr = copy.deepcopy(tfr_epochs1)\n",
    "            both_tfr_data_tfr.data = both_tfr_data\n",
    "\n",
    "            #Correction is applied to all epoch and channel together in the following way: 1.Calculate the mean signal of the baseline period. 2.Subtract this mean from the entire epoch.\n",
    "            both_tfr_data_tfr.apply_baseline(mode='zscore', baseline=baseline)\n",
    "\n",
    "            num_of_cond1_trials = tfr_epochs1.data.shape[0]\n",
    "            epochs_power1 = np.mean(both_tfr_data_tfr.data[:num_of_cond1_trials,:,:,:],axis=(0,1)) # elec, freqs, time\n",
    "            epochs_power2 = np.mean(both_tfr_data_tfr.data[num_of_cond1_trials:,:,:,:],axis=(0,1)) # elec, freqs, time\n",
    "\n",
    "            epochs_time_diff.append(np.mean(cont_epochs1,axis=0) - np.mean(cont_epochs2,axis=0))\n",
    "        else: # apply baseline seperately\n",
    "            tfr_epochs1 = tfr_morlet(cont_epochs1, freqs, n_cycles=n_cycles, decim=decim, average=True, return_itc=False)\n",
    "            tfr_epochs2 = tfr_morlet(cont_epochs2, freqs, n_cycles=n_cycles, decim=decim, average=True, return_itc=False)\n",
    "            ## TODO: The baseline maybe should be applied together for both conditions\n",
    "            tfr_epochs1.apply_baseline(mode='zscore', baseline=baseline)\n",
    "            tfr_epochs2.apply_baseline(mode='zscore', baseline=baseline)\n",
    "            epochs_power1 = tfr_epochs1.data # elec, freqs, time\n",
    "            epochs_power2 = tfr_epochs2.data # elec, freqs, time\n",
    "\n",
    "            epochs_time_diff.append(np.mean(cont_epochs1.get_data(),axis=0) - np.mean(cont_epochs2.get_data(),axis=0))\n",
    "\n",
    "        means_diff = epochs_power1-epochs_power2\n",
    "        epochs_power_diff.append(means_diff)\n",
    "\n",
    "    # (n_epochs, n_channels, n_freqs, n_times)\n",
    "    epochs_power_diff_arr = np.zeros((len(cfg['subs']),len(cfg['electrodes']),len(freqs),len(times)))\n",
    "    for s,subject in enumerate(cfg['subs']):\n",
    "        epochs_power_diff_arr[s,:,:,:] = epochs_power_diff[s]\n",
    "\n",
    "    #### Define adjacency for statistics\n",
    "    tfr_epochs = tfr_epochs1\n",
    "    sensor_adjacency, ch_names = mne.channels.find_ch_adjacency(tfr_epochs.info,ch_type=None)\n",
    "    use_idx = [ch_names.index(ch_name) for ch_name in tfr_epochs.ch_names]\n",
    "    sensor_adjacency = sensor_adjacency[use_idx][:, use_idx]\n",
    "    assert sensor_adjacency.shape == (len(tfr_epochs.ch_names), len(tfr_epochs.ch_names))\n",
    "    assert epochs_power_diff_arr.shape == (len(cfg['subs']), len(tfr_epochs.ch_names), len(tfr_epochs.freqs), len(tfr_epochs.times))\n",
    "    adjacency = mne.stats.combine_adjacency(sensor_adjacency, len(tfr_epochs.freqs), len(tfr_epochs.times))\n",
    "    assert adjacency.shape[0] == adjacency.shape[1] == len(tfr_epochs.ch_names) * len(tfr_epochs.freqs) * len(tfr_epochs.times)\n",
    "\n",
    "    ### run cluster permutation\n",
    "    degrees_of_freedom = len(cfg['subs']) - 1\n",
    "    t_thresh = scipy.stats.t.ppf(1 - p_value_pixels / 2, df=degrees_of_freedom)\n",
    "    T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(epochs_power_diff_arr[...,cluster_start_time_index:], n_permutations=n_permutations, threshold=t_thresh, tail=tail,  out_type='mask', verbose=True, stat_fun=test_per_voxel)\n",
    "\n",
    "    ############# plot\n",
    "    T_obs_plot = np.nan * np.ones_like(T_obs)\n",
    "    for c, clust_p_val in zip(clusters, cluster_p_values):\n",
    "        if clust_p_val <= p_value:\n",
    "            T_obs_plot[c] = T_obs[c]\n",
    "    mean_epochs_time_diff = np.nanmean(epochs_time_diff,axis=0)\n",
    "\n",
    "    padded_t_obs = np.zeros((len(cfg['electrodes']), len(freqs),len(times)))\n",
    "    padded_t_obs_plot = np.zeros((len(cfg['electrodes']), len(freqs),len(times)))\n",
    "    padded_t_obs[:,:,cluster_start_time_index:]=T_obs\n",
    "    padded_t_obs_plot[:,:,cluster_start_time_index:]=T_obs_plot\n",
    "\n",
    "    for ch_idx, elecd in enumerate(cfg['electrodes']):\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "        fig.subplots_adjust(left=0.12,bottom= 0.08,right= 0.96, top=0.85, wspace=0.2, hspace=0.3)\n",
    "        plot_clusters_map(ax1,padded_t_obs,ch_idx,tfr_epochs,t_thresh,padded_t_obs_plot)\n",
    "        plot_elecds_erps(ax2,mean_epochs_time_diff,ch_idx,tfr_epochs)\n",
    "        plt.ioff()\n",
    "        plt.savefig(f'{fig_output_dir}/timeFreq_clusters_{contrast_name}_{tfr_epochs.ch_names[ch_idx]}.png',bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run many contrasts at once"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now computeing {'TOA_cond': 'T', 'Vigilance': 'Wn'} and baseline\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "89 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: zscore)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample x must be one-dimensional.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 37>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     42\u001B[0m apply_baseline_together\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     43\u001B[0m contrast_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcontrast\u001B[38;5;241m.\u001B[39mtitle()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_AverageBaseline-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mapply_baseline_together\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_per_voxel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 44\u001B[0m \u001B[43mgetClustersPerConditions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcond_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcond_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontrast_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43mapply_baseline_together\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapply_baseline_together\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcluster_start_time_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime0_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtest_per_voxel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWilcox\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36mgetClustersPerConditions\u001B[1;34m(cond_1, cond_2, contrast_name, apply_baseline_together, baseline, cluster_start_time_index, test_per_voxel)\u001B[0m\n\u001B[0;32m     80\u001B[0m degrees_of_freedom \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(cfg[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubs\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     81\u001B[0m t_thresh \u001B[38;5;241m=\u001B[39m scipy\u001B[38;5;241m.\u001B[39mstats\u001B[38;5;241m.\u001B[39mt\u001B[38;5;241m.\u001B[39mppf(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m p_value_pixels \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m, df\u001B[38;5;241m=\u001B[39mdegrees_of_freedom)\n\u001B[1;32m---> 82\u001B[0m T_obs, clusters, cluster_p_values, H0 \u001B[38;5;241m=\u001B[39m \u001B[43mpermutation_cluster_1samp_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs_power_diff_arr\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mcluster_start_time_index\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_permutations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_permutations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_thresh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtail\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtail\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mout_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmask\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstat_fun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_per_voxel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m############# plot\u001B[39;00m\n\u001B[0;32m     85\u001B[0m T_obs_plot \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mones_like(T_obs)\n",
      "File \u001B[1;32m<decorator-gen-332>:10\u001B[0m, in \u001B[0;36mpermutation_cluster_1samp_test\u001B[1;34m(X, threshold, n_permutations, tail, stat_fun, adjacency, n_jobs, seed, max_step, exclude, step_down_p, t_power, out_type, check_disjoint, buffer_size, verbose)\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\mne\\stats\\cluster_level.py:1207\u001B[0m, in \u001B[0;36mpermutation_cluster_1samp_test\u001B[1;34m(X, threshold, n_permutations, tail, stat_fun, adjacency, n_jobs, seed, max_step, exclude, step_down_p, t_power, out_type, check_disjoint, buffer_size, verbose)\u001B[0m\n\u001B[0;32m   1137\u001B[0m \u001B[38;5;124;03m\"\"\"Non-parametric cluster-level paired t-test.\u001B[39;00m\n\u001B[0;32m   1138\u001B[0m \n\u001B[0;32m   1139\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1204\u001B[0m \u001B[38;5;124;03m.. footbibliography::\u001B[39;00m\n\u001B[0;32m   1205\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1206\u001B[0m stat_fun, threshold \u001B[38;5;241m=\u001B[39m _check_fun(X, stat_fun, threshold, tail)\n\u001B[1;32m-> 1207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_permutation_cluster_test\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1208\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mX\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthreshold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_permutations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_permutations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtail\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtail\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1209\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstat_fun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstat_fun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madjacency\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madjacency\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_down_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep_down_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1211\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_power\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_power\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_disjoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_disjoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbuffer_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\mne\\stats\\cluster_level.py:874\u001B[0m, in \u001B[0;36m_permutation_cluster_test\u001B[1;34m(X, threshold, n_permutations, tail, stat_fun, adjacency, n_jobs, seed, max_step, exclude, step_down_p, t_power, out_type, check_disjoint, buffer_size)\u001B[0m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexclude must be the same shape as X[0]\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    872\u001B[0m \u001B[38;5;66;03m# Step 1: Calculate t-stat for original data\u001B[39;00m\n\u001B[0;32m    873\u001B[0m \u001B[38;5;66;03m# -------------------------------------------------------------\u001B[39;00m\n\u001B[1;32m--> 874\u001B[0m t_obs \u001B[38;5;241m=\u001B[39m \u001B[43mstat_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    875\u001B[0m _validate_type(t_obs, np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreturn value of stat_fun\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    876\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstat_fun(H1): min=\u001B[39m\u001B[38;5;132;01m%f\u001B[39;00m\u001B[38;5;124m max=\u001B[39m\u001B[38;5;132;01m%f\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (np\u001B[38;5;241m.\u001B[39mmin(t_obs), np\u001B[38;5;241m.\u001B[39mmax(t_obs)))\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36mstat_fun_wilcox\u001B[1;34m(X)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstat_fun_wilcox\u001B[39m(X):\n\u001B[1;32m----> 2\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mscipy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstats\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwilcoxon\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39mstatistic\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:3123\u001B[0m, in \u001B[0;36mwilcoxon\u001B[1;34m(x, y, zero_method, correction, alternative, mode)\u001B[0m\n\u001B[0;32m   3121\u001B[0m     d \u001B[38;5;241m=\u001B[39m asarray(x)\n\u001B[0;32m   3122\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m d\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m-> 3123\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSample x must be one-dimensional.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   3124\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3125\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmap\u001B[39m(asarray, (x, y))\n",
      "\u001B[1;31mValueError\u001B[0m: Sample x must be one-dimensional."
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "contrasts = {}\n",
    "# contrasts[\"allSubs_RandvsFixed_Wn\"] = {'cond_1':{'TOA_cond':'Rand','Vigilance':'Wn'},'cond_2':{'TOA_cond':'Fixed','Vigilance':'Wn'}}\n",
    "# contrasts[\"allSubs_RandvsFixed_N2\"] = {'cond_1':{'TOA_cond':'Rand','Vigilance':'N2'},'cond_2':{'TOA_cond':'Fixed','Vigilance':'N2'}}\n",
    "# contrasts[\"allSubs_RandvsFixed_N3\"] = {'cond_1':{'TOA_cond':'Rand','Vigilance':'N3'},'cond_2':{'TOA_cond':'Fixed','Vigilance':'N3'}}\n",
    "# contrasts[\"allSubs_RandvsFixed_REM\"] = {'cond_1':{'TOA_cond':'Rand','Vigilance':'REM'},'cond_2':{'TOA_cond':'Fixed','Vigilance':'REM'}}\n",
    "# # contrasts[\"allSubs_T_WnvsN2\"] = {'cond_1':{'TOA_cond':'T','Vigilance':'Wn'},'cond_2':{'TOA_cond':'T','Vigilance':'N2'}}\n",
    "# # contrasts['allSubs_T_WnvsN3'] = {'cond_1':{'TOA_cond':'T','Vigilance':'Wn'},'cond_2':{'TOA_cond':'T','Vigilance':'N3'}}\n",
    "# # contrasts['allSubs_T_WnvsREM'] = {'cond_1':{'TOA_cond':'T','Vigilance':'Wn'},'cond_2':{'TOA_cond':'T','Vigilance':'REM'}}\n",
    "# contrasts['allSubs_TvsRand_Wn'] = {'cond_1':{'TOA_cond':'T','Vigilance':'Wn'},'cond_2':{'TOA_cond':'Rand','Vigilance':'Wn'}}\n",
    "# contrasts['allSubs_TvsRand_N2'] = {'cond_1':{'TOA_cond':'T','Vigilance':'N2'},'cond_2':{'TOA_cond':'Rand','Vigilance':'N2'}}\n",
    "# contrasts['allSubs_TvsRand_N3'] = {'cond_1':{'TOA_cond':'T','Vigilance':'N3'},'cond_2':{'TOA_cond':'Rand','Vigilance':'N3'}}\n",
    "# contrasts['allSubs_TvsRand_REM'] = {'cond_1':{'TOA_cond':'T','Vigilance':'REM'},'cond_2':{'TOA_cond':'Rand','Vigilance':'REM'}}\n",
    "# contrasts['allSubs_TvsFixed_Wn'] = {'cond_1':{'TOA_cond':'T','Vigilance':'Wn'},'cond_2':{'TOA_cond':'Fixed','Vigilance':'Wn'}}\n",
    "# contrasts['allSubs_TvsFixed_N2'] = {'cond_1':{'TOA_cond':'T','Vigilance':'N2'},'cond_2':{'TOA_cond':'Fixed','Vigilance':'N2'}}\n",
    "# contrasts['allSubs_TvsFixed_N3'] = {'cond_1':{'TOA_cond':'T','Vigilance':'N3'},'cond_2':{'TOA_cond':'Fixed','Vigilance':'N3'}}\n",
    "# contrasts['allSubs_TvsFixed_REM'] = {'cond_1':{'TOA_cond':'T','Vigilance':'REM'},'cond_2':{'TOA_cond':'Fixed','Vigilance':'REM'}}\n",
    "\n",
    "#### Vs. Baseline\n",
    "\n",
    "contrasts['allSubs_TvsBaseline_Wn'] = {'cond_1':{'TOA_cond':'T','Vigilance':'Wn'},'cond_2':'baseline'}\n",
    "contrasts['allSubs_TvsBaseline_N2'] = {'cond_1':{'TOA_cond':'T','Vigilance':'N2'},'cond_2':'baseline'}\n",
    "contrasts['allSubs_TvsBaseline_N3'] = {'cond_1':{'TOA_cond':'T','Vigilance':'N3'},'cond_2':'baseline'}\n",
    "contrasts['allSubs_TvsBaseline_REM'] = {'cond_1':{'TOA_cond':'T','Vigilance':'REM'},'cond_2':'baseline'}\n",
    "\n",
    "contrasts['allSubs_RandvsBaseline_Wn'] = {'cond_1':{'TOA_cond':'Rand','Vigilance':'Wn'},'cond_2':'baseline'}\n",
    "contrasts['allSubs_RandvsBaseline_N2'] = {'cond_1':{'TOA_cond':'Rand','Vigilance':'N2'},'cond_2':'baseline'}\n",
    "contrasts['allSubs_RandvsBaseline_N3'] = {'cond_1':{'TOA_cond':'Rand','Vigilance':'N3'},'cond_2':'baseline'}\n",
    "contrasts['allSubs_RandvsBaseline_REM'] = {'cond_1':{'TOA_cond':'Rand','Vigilance':'REM'},'cond_2':'baseline'}\n",
    "\n",
    "contrasts['allSubs_FixedvsBaseline_Wn'] = {'cond_1':{'TOA_cond':'Fixed','Vigilance':'Wn'},'cond_2':'baseline'}\n",
    "contrasts['allSubs_FixedvsBaseline_N2'] = {'cond_1':{'TOA_cond':'Fixed','Vigilance':'N2'},'cond_2':'baseline'}\n",
    "contrasts['allSubs_FixedvsBaseline_N3'] = {'cond_1':{'TOA_cond':'Fixed','Vigilance':'N3'},'cond_2':'baseline'}\n",
    "contrasts['allSubs_FixedvsBaseline_REM'] = {'cond_1':{'TOA_cond':'Fixed','Vigilance':'REM'},'cond_2':'baseline'}\n",
    "\n",
    "for contrast in contrasts:\n",
    "    cond_1 = contrasts[contrast]['cond_1']\n",
    "    cond_2 = contrasts[contrast]['cond_2']\n",
    "    print(f'Now computeing {cond_1} and {cond_2}')\n",
    "    test_per_voxel='Wilcox'\n",
    "    apply_baseline_together=True\n",
    "    contrast_name = f\"{contrast.title()}_AverageBaseline-{apply_baseline_together}-{test_per_voxel}\"\n",
    "    getClustersPerConditions(cond_1, cond_2, contrast_name,apply_baseline_together=apply_baseline_together, cluster_start_time_index=time0_i,test_per_voxel='Wilcox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "946b629e9a35e0bdbfd20594fab2712eb62be0364242a9946815d6a663dae4aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}