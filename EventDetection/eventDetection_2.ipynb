{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37830"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.stats\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "import gc\n",
    "import os\n",
    "import copy\n",
    "from scipy.signal import firwin, lfilter, find_peaks\n",
    "import pickle\n",
    "from os.path import exists\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne import create_info\n",
    "from IPython.utils import io\n",
    "import yasa\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matlab\n",
    "import matlab.engine\n",
    "import os\n",
    "import shutil\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import freqz\n",
    "from scipy import signal\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def overlap(a, b):\n",
    "    return a[1] >= b[0] and a[0] <= b[1]\n",
    "\n",
    "def restart_output_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = \"C:\\\\Users\\\\User\\\\Cloud-Drive\\\\BigFiles\\\\OmissionExpOutput\\\\eventDetection\\\\try2\\\\imported_eventDetectionChan\\\\no_filters\"\n",
    "sub = '33'\n",
    "sleep_data_file_num = '2'\n",
    "\n",
    "\n",
    "import_type = \"eventDetectionChan\"\n",
    "event_detection_dir_name = 'eventDetection'\n",
    "electrode_column_name = 'electrode'\n",
    "header_edf = np.array(['Onset',\"Duration\",\"Annotation\"])\n",
    "spindles_output_columns =  ['spindleStartTime', 'spindleEndTime', 'peakTime', 'peakEnergy', 'peakEnergyNorm', 'freqSpindle', 'spindleDuration/SR', 'PowerSP', 'PowerAlpha', 'sleepStage']\n",
    "kcomp_df_columns = ['pos_i','pos_amp','neg_i','neg_amp','power',electrode_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edfViewFormat_scoring_dict(score):\n",
    "    if score == 0:\n",
    "        return 'W'\n",
    "    elif score ==1:\n",
    "        return 'N1'\n",
    "    elif score ==2:\n",
    "        return 'N2'\n",
    "    elif score ==3:\n",
    "        return 'N3'\n",
    "    elif score ==4:\n",
    "        return 'TREM'\n",
    "    elif score ==5:\n",
    "        return 'PREM'\n",
    "    elif score ==6:\n",
    "        return 'MOVE'\n",
    "    elif score ==7:\n",
    "        return 'ARTIFACT'\n",
    "    else:\n",
    "        Exception('no such score')\n",
    "\n",
    "def get_edfViewFormat_scoring(scoring):\n",
    "    new_format_score = np.zeros((len(scoring),3), dtype=object)\n",
    "    for ind, score in enumerate(scoring):\n",
    "            new_format_score[ind,:] = [30*ind,30,edfViewFormat_scoring_dict(score)] ## onset (sec), duration, desc\n",
    "    return new_format_score\n",
    "\n",
    "def group_events(filterd_events_allElectrodes, start_column_name, end_column_name,power_column_name,electrode_column_name):\n",
    "    # The grouping is done such that you get 1 event per time frame.\n",
    "    # In the single condition, only one electrode is sufficiant to include event.\n",
    "    # In the multi condition event will be includede only if it appears in sevral electrodes\n",
    "    # The picked electrode is the one where the event is with the most power\n",
    "    filterd_events_allElectrodes.sort_values(by=[start_column_name],inplace=True) \n",
    "    filterd_events_allElectrodes.reset_index(drop=True, inplace=True)\n",
    "    deleted = filterd_events_allElectrodes.copy(deep=True)\n",
    "    filtered = pd.DataFrame([], columns = deleted.columns)\n",
    "    filtered_moreThan1 = pd.DataFrame([], columns = deleted.columns)\n",
    "    simultan = pd.DataFrame([], columns = deleted.columns)\n",
    "\n",
    "    while len(deleted)>0:\n",
    "        if len(simultan)==0:\n",
    "            simultan = pd.concat([simultan, deleted.iloc[[0]]])\n",
    "            deleted.drop(deleted.index[0], axis=0, inplace=True)\n",
    "            still_overlap = True\n",
    "        else:\n",
    "            while still_overlap == True and len(deleted)>0:\n",
    "                still_overlap = False\n",
    "                simultan.reset_index(drop=True, inplace=True) # make sure indexes pair with number of rows\n",
    "\n",
    "                ## check now_overlap_all_in_simultan:\n",
    "                for index, simultan_row in simultan.iterrows():\n",
    "                    simultan_0 = simultan_row[start_column_name]\n",
    "                    simultan_1 = simultan_row[end_column_name]\n",
    "                    deleted_0 = deleted.iloc[0][start_column_name]\n",
    "                    deleted_1 = deleted.iloc[0][end_column_name]\n",
    "                    if overlap([simultan_0,simultan_1],[deleted_0,deleted_1]):\n",
    "                        simultan = pd.concat([simultan, deleted.iloc[[0]]])\n",
    "                        deleted.drop(deleted.index[0], axis=0, inplace=True)\n",
    "                        still_overlap = True\n",
    "                        break\n",
    "                if still_overlap: continue\n",
    "                else:\n",
    "                    ## check max ps and add to filt\n",
    "                    # if len(simultan)>1:\n",
    "                    #     print('hu')\n",
    "                    simultan.sort_values(by=[power_column_name],ascending=False,inplace=True)\n",
    "                    row_df = simultan.iloc[[0]]\n",
    "                    row_df.iat[0, row_df.columns.get_loc(electrode_column_name)] = np.unique(np.array(simultan[electrode_column_name]))\n",
    "                    filtered = pd.concat([filtered,row_df])\n",
    "                    if len(simultan) > 1: filtered_moreThan1 = pd.concat([filtered_moreThan1,row_df])\n",
    "                    simultan = pd.DataFrame([], columns = deleted.columns)                    \n",
    "        \n",
    "    filtered.reset_index(drop=True, inplace=True) # make sure indexes pair with number of rows\n",
    "    filtered_moreThan1.reset_index(drop=True, inplace=True) # make sure indexes pair with number of rows\n",
    "    return filtered, filtered_moreThan1\n",
    "    # allsubsdata_perFile[id][uniqeElctd_ss_key] = filtered   \n",
    "    # allsubsdata_perFile[id][uniqeElctds_ss_key] = filtered_moreThan1   \n",
    "    # print(f\"sub:{id}, before filt:{np.shape(allsubsdata_perFile[id][ss_key_to_use])[0]}, after:{np.shape(allsubsdata_perFile[id][uniqeElctd_ss_key])[0]}, after>1:{np.shape(allsubsdata_perFile[id][uniqeElctds_ss_key])[0]}\")\n",
    "\n",
    "def preform_event_comparison(all_event_manu,all_event_auto,file_id,event_tag):\n",
    "\n",
    "    ## get the array of before manual scanning\n",
    "    all_event_auto = np.delete(all_event_auto, np.where(all_event_auto[:, 2] == \"Annotation\")[0], axis=0)\n",
    "    all_event_auto[:,[0,1]] = [np.double(x) for x in all_event_auto[:,[0,1]]]\n",
    "    event_ind = np.array([],dtype=int)\n",
    "    for ind_i, desc in enumerate(all_event_auto[:,2]):\n",
    "        if event_tag in desc:\n",
    "            event_ind = np.append(event_ind, ind_i)\n",
    "    all_event_auto = all_event_auto[event_ind,:]\n",
    "    all_event_auto[:, 1] = np.where(all_event_auto[:, 1] < 0.1, all_event_auto[:, 1] * configu['sample_freq'], all_event_auto[:, 1])# solves the division by sample rate issue\n",
    "\n",
    "    ## get the array of after manual scanning\n",
    "    all_event_manu = np.delete(all_event_manu, np.where(all_event_manu[:, 2] == \"Annotation\")[0], axis=0)\n",
    "    all_event_manu[:,[0,1]] = [np.double(x) for x in all_event_manu[:,[0,1]]]\n",
    "    event_ind = np.array([],dtype=int)\n",
    "    for ind_i, desc in enumerate(all_event_manu[:,2]):\n",
    "        if event_tag == 'kc':\n",
    "            if event_tag in desc or \"Kcomp\" in desc:\n",
    "                event_ind = np.append(event_ind, ind_i)\n",
    "        else:\n",
    "            if event_tag in desc:\n",
    "                event_ind = np.append(event_ind, ind_i)\n",
    "    all_event_manu = all_event_manu[event_ind,:]\n",
    "    all_event_manu[:, 1] = np.where(all_event_manu[:, 1] < 0.1, all_event_manu[:, 1] * configu['sample_freq'], all_event_manu[:, 1])# solves the division by sample rate issue\n",
    "\n",
    "\n",
    "    ## compare to find rate of TP and FP\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    for ss_auto in all_event_auto:\n",
    "        found = False\n",
    "        for ss_manu in all_event_manu:\n",
    "            if overlap([ss_auto[0],ss_auto[0]+ss_auto[1]],[ss_manu[0],ss_manu[0]+ss_manu[1]]):\n",
    "                TP +=1\n",
    "                found = True\n",
    "                break\n",
    "        if found == False:\n",
    "            FP +=1\n",
    "\n",
    "    # FN = 0\n",
    "    # for ss_manu in all_ss_manu:\n",
    "    #     found = False\n",
    "    #     for ss_auto in all_ss_auto:\n",
    "    #         if overlap([ss_auto[0],ss_auto[0]+ss_auto[1]],[ss_manu[0],ss_manu[0]+ss_manu[1]]):\n",
    "    #             found = True\n",
    "    #             break\n",
    "    #     if found == False:\n",
    "    #         FN +=1\n",
    "\n",
    "    Positive = np.shape(all_event_manu)[0]   \n",
    "    hitRate = TP/Positive\n",
    "    #missRate = FN/Positive\n",
    "    falseDiscoveryRate = FP/(FP+TP)\n",
    "    \n",
    "    comparison = [file_id, Positive, TP, FP,hitRate, falseDiscoveryRate]\n",
    "    return comparison\n",
    "\n",
    "def preform_ss_comparison_yasa(manu_detection_filepath,sub,sleep_data_file_num,yasa_ss_summary):\n",
    "    file_id = f'{sub}_{sleep_data_file_num}'\n",
    "    EEG_data, configu, datafile_scoring, exmp_scoring_upsampled = get_eeg_data(pkl_dir,sub,sleep_data_file_num)\n",
    "\n",
    "    indeces_ss_auto = np.zeros(np.shape(EEG_data)[1]);\n",
    "    auto_startTime_inSamples_arr = np.array(yasa_ss_summary['Start']* configu['sample_freq'],dtype=np.int64) \n",
    "    auto_endTime_inSamples_arr = np.array(yasa_ss_summary['End']* configu['sample_freq'],dtype=np.int64) \n",
    "    for ss_start,ss_end in zip(auto_startTime_inSamples_arr,auto_endTime_inSamples_arr):\n",
    "        indeces_ss_auto[ss_start:ss_end] = 1;\n",
    "\n",
    "    ## get the array of after manual scanning\n",
    "    all_ss_manu = np.loadtxt(manual_detection_filepath, delimiter=\"\\t\",dtype='object')\n",
    "    all_ss_manu = np.delete(all_ss_manu, np.where(all_ss_manu[:, 2] == \"Annotation\")[0], axis=0)\n",
    "    all_ss_manu[:,[0,1]] = [np.double(x) for x in all_ss_manu[:,[0,1]]]\n",
    "    ss_ind = np.array([],dtype=int)\n",
    "    for ind_i, desc in enumerate(all_ss_manu[:,2]):\n",
    "        if (\"SS\" in desc) or (\"ss\" in desc):\n",
    "            ss_ind = np.append(ss_ind, ind_i)\n",
    "    all_ss_manu = all_ss_manu[ss_ind,:]\n",
    "    all_ss_manu[:, 1] = np.where(all_ss_manu[:, 1] < 0.1, all_ss_manu[:, 1] * configu['sample_freq'], all_ss_manu[:, 1])# solves the division by sample rate issue\n",
    "\n",
    "    indeces_ss_manu = np.zeros(np.shape(EEG_data)[1]);\n",
    "    manu_startTime_inSamples_arr = np.array(all_ss_manu[:,0]* configu['sample_freq'],dtype=np.int64)\n",
    "    manu_duration_inSamples_arr = np.array(all_ss_manu[:,1]* configu['sample_freq'],dtype=np.int64) \n",
    "    for ss_start,ss_dur in zip(manu_startTime_inSamples_arr,manu_duration_inSamples_arr):\n",
    "        indeces_ss_manu[ss_start : ss_start+ss_dur] = 1;\n",
    "\n",
    "    return yasa.compare_detection(indices_detection=np.squeeze(np.nonzero(indeces_ss_auto)),\n",
    "                                  indices_groundtruth=np.squeeze(np.nonzero(indeces_ss_manu)),\n",
    "                                   max_distance=int(configu['sample_freq']))\n",
    "\n",
    "# returns False if file doesnt exists. If it does, return: data, configu, datafile_scoring, exmp_scoring_upsampled\n",
    "def get_eeg_data(pkl_dir,sub,sleep_data_file_num):\n",
    "    import_path = f'{pkl_dir}\\\\{import_type}_sub-{sub}_sleep-{sleep_data_file_num}.pkl'\n",
    "    if os.path.isfile(import_path):\n",
    "        with open(import_path, \"rb\") as file:  [allsubsdata_perFile, configu] = pickle.load(file)\n",
    "        id = f\"{sub}_{sleep_data_file_num}\"\n",
    "        EEG_data = allsubsdata_perFile[id]['data']; ## shape (electrode, time)\n",
    "        datafile_scoring = allsubsdata_perFile[id]['scoring'] ## shape (time/sampling/30)\n",
    "        exmp_scoring_upsampled = yasa.hypno_upsample_to_data(datafile_scoring, 1/30, EEG_data, sf_data=configu['sample_freq'])\n",
    "        return EEG_data, configu, datafile_scoring, exmp_scoring_upsampled\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def kc_detection(eeg_timeseries, sample_rate,included_sleepstages, sleepstages_upsampled):\n",
    "    # Subtract mean from x\n",
    "    eeg_timeseries = eeg_timeseries - np.mean(eeg_timeseries)\n",
    "\n",
    "    # Bandpass filter parameters\n",
    "    a = firwin(100, [0.25/sample_rate,5/sample_rate], pass_zero='bandpass')\n",
    "    filtered_eeg = lfilter(a, [1], eeg_timeseries)\n",
    "\n",
    "    # Invert the data to find troughs instead of peaks (actually troughs in original signal)\n",
    "    minimas_indexes, minimas_popr = find_peaks(np.max(filtered_eeg) - filtered_eeg, distance=1.5*sample_rate,width=0.15*sample_rate)\n",
    "    minimas = filtered_eeg[minimas_indexes]\n",
    "    minimas_width = minimas_popr['widths']\n",
    "\n",
    "    # Thresholding\n",
    "    mm = minimas[minimas <= -45]\n",
    "    pos = np.where(np.isin(minimas, mm))[0]\n",
    "    sig_minimas_indxs = minimas_indexes[pos]\n",
    "    minimas_width = minimas_width[pos]\n",
    "\n",
    "    # Further filtering of peaks and computing durations\n",
    "    durations = []\n",
    "    kc_onset = []\n",
    "    kc_end = []\n",
    "    kc_min_pos= []\n",
    "    kc_min_power= []\n",
    "    kc_max_pos= []\n",
    "    kc_max_power= []\n",
    "    kc_peak_difference = [];\n",
    "\n",
    "    for sig_minima_samp_i, sig_minima_width in zip(sig_minimas_indxs, minimas_width):\n",
    "        baseline_before_minima = np.mean(filtered_eeg[sig_minima_samp_i-int(1.5*sample_rate) : sig_minima_samp_i - int(sample_rate*0.5)]) # mean 1-2 sec before it\n",
    "        if filtered_eeg[sig_minima_samp_i] < 2.5* baseline_before_minima and \\\n",
    "        sleepstages_upsampled[sig_minima_samp_i] in included_sleepstages :\n",
    "            # Find the subsequent positive peak after the detected negative peak (within 1 second after the negative peak)\n",
    "            maximas_samp_relative_i, maximas_popr = find_peaks(filtered_eeg[sig_minima_samp_i:], distance=sample_rate, width=0.15*sample_rate) \n",
    "            \n",
    "            if maximas_samp_relative_i.size > 0:\n",
    "                maxima_samp_i = sig_minima_samp_i+maximas_samp_relative_i[0]\n",
    "                maxima_val = filtered_eeg[maxima_samp_i]\n",
    "                maxima_width = maximas_popr['widths'][0] \n",
    "                kc_duration = ( maxima_samp_i - (sig_minima_samp_i - (sig_minima_width/2))) / sample_rate # (end of kc - start of kc) / samplerate\n",
    "                negative_peak = filtered_eeg[sig_minima_samp_i]\n",
    "                positive_peak = filtered_eeg[sig_minima_samp_i + maximas_samp_relative_i[0]]\n",
    "                peak_difference = positive_peak - negative_peak\n",
    "\n",
    "                # Filtering conditions: \n",
    "                if maxima_val > 20 and \\\n",
    "                    kc_duration >= 0.5 and kc_duration <= 2.5 and \\\n",
    "                    sig_minima_width < maxima_width and \\\n",
    "                    baseline_before_minima < maxima_val and \\\n",
    "                    peak_difference >= 100 :\n",
    "                    # sig_minima_width / configu['sample_freq'] < negative_peak / 170 and \n",
    "                    durations.append(kc_duration)\n",
    "                    kc_onset.append(sig_minima_samp_i - (sig_minima_width/2))\n",
    "                    kc_min_pos.append(sig_minima_samp_i)\n",
    "                    kc_min_power.append(negative_peak)\n",
    "                    kc_max_power.append(positive_peak)\n",
    "                    kc_max_pos.append(maxima_samp_i)\n",
    "                    kc_end.append(sig_minima_samp_i - (sig_minima_width/2) + (kc_duration*sample_rate))\n",
    "                    kc_peak_difference.append(peak_difference)\n",
    "\n",
    "    res = {\n",
    "        \"durations\": durations,\n",
    "        \"kc_onset\": kc_onset,\n",
    "        \"kc_min_pos\": kc_min_pos,\n",
    "        \"kc_min_power\": kc_min_power,\n",
    "        \"kc_max_power\": kc_max_power,\n",
    "        \"kc_max_pos\": kc_max_pos,\n",
    "        \"kc_peak_difference\": kc_peak_difference,\n",
    "        \"kc_end\": kc_end\n",
    "    }\n",
    "\n",
    "    return res \n",
    "\n",
    "def preform_kc_comparison_yasa(manu_detection_filepath,sub,sleep_data_file_num,auto_detection_filepath):\n",
    "    EEG_data, configu, datafile_scoring, exmp_scoring_upsampled = get_eeg_data(pkl_dir,sub,sleep_data_file_num)\n",
    "\n",
    "    ## get the array of after manual scanning\n",
    "    all_kc_auto = np.loadtxt(auto_detection_filepath, delimiter=\"\\t\",dtype='object')\n",
    "    all_kc_auto = np.delete(all_kc_auto, np.where(all_kc_auto[:, 2] == \"Annotation\")[0], axis=0)\n",
    "    all_kc_auto[:,[0,1]] = [np.double(x) for x in all_kc_auto[:,[0,1]]]\n",
    "    ss_ind = np.array([],dtype=int)\n",
    "    for ind_i, desc in enumerate(all_kc_auto[:,2]):\n",
    "        if (\"kc\" in desc) or (\"Kcomp\" in desc):\n",
    "            ss_ind = np.append(ss_ind, ind_i)\n",
    "    all_kc_auto = all_kc_auto[ss_ind,:]\n",
    "    all_kc_auto[:, 1] = np.where(all_kc_auto[:, 1] < 0.1, all_kc_auto[:, 1] * configu['sample_freq'], all_kc_auto[:, 1])# solves the division by sample rate issue\n",
    "\n",
    "    indeces_kc_auto = np.zeros(np.shape(EEG_data)[1]);\n",
    "    auto_startTime_inSamples_arr = np.array(all_kc_auto[:,0]* configu['sample_freq'],dtype=np.int64)\n",
    "    auto_duration_inSamples_arr = np.array(all_kc_auto[:,1]* configu['sample_freq'],dtype=np.int64) \n",
    "    for kc_start,kc_dur in zip(auto_startTime_inSamples_arr,auto_duration_inSamples_arr):\n",
    "        indeces_kc_auto[kc_start : kc_start+kc_dur] = 1;\n",
    "\n",
    "\n",
    "    ## get the array of after manual scanning\n",
    "    all_kc_manu = np.loadtxt(manu_detection_filepath, delimiter=\"\\t\",dtype='object')\n",
    "    all_kc_manu = np.delete(all_kc_manu, np.where(all_kc_manu[:, 2] == \"Annotation\")[0], axis=0)\n",
    "    all_kc_manu[:,[0,1]] = [np.double(x) for x in all_kc_manu[:,[0,1]]]\n",
    "    ss_ind = np.array([],dtype=int)\n",
    "    for ind_i, desc in enumerate(all_kc_manu[:,2]):\n",
    "        if (\"kc\" in desc) or (\"Kcomp\" in desc):\n",
    "            ss_ind = np.append(ss_ind, ind_i)\n",
    "    all_kc_manu = all_kc_manu[ss_ind,:]\n",
    "    all_kc_manu[:, 1] = np.where(all_kc_manu[:, 1] < 0.1, all_kc_manu[:, 1] * configu['sample_freq'], all_kc_manu[:, 1])# solves the division by sample rate issue\n",
    "\n",
    "    indeces_kc_manu = np.zeros(np.shape(EEG_data)[1]);\n",
    "    manu_startTime_inSamples_arr = np.array(all_kc_manu[:,0]* configu['sample_freq'],dtype=np.int64)\n",
    "    manu_duration_inSamples_arr = np.array(all_kc_manu[:,1]* configu['sample_freq'],dtype=np.int64) \n",
    "    for kc_start,kc_dur in zip(manu_startTime_inSamples_arr,manu_duration_inSamples_arr):\n",
    "        indeces_kc_manu[kc_start : kc_start+kc_dur] = 1;\n",
    "\n",
    "    return yasa.compare_detection(indices_detection=np.squeeze(np.nonzero(indeces_kc_auto)),\n",
    "                                  indices_groundtruth=np.squeeze(np.nonzero(indeces_kc_manu)),\n",
    "                                   max_distance=int(configu['sample_freq']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save only scoring. one file\n",
    "sub = '33'\n",
    "sleep_data_file_num = '2'\n",
    "\n",
    "id = f\"{sub}_{sleep_data_file_num}\"\n",
    "EEG_data, configu, datafile_scoring, exmp_scoring_upsampled = get_eeg_data(pkl_dir,sub,sleep_data_file_num)\n",
    "all_events_with_header = np.vstack([header_edf,get_edfViewFormat_scoring(datafile_scoring)])\n",
    "np.savetxt(f\"{pkl_dir}\\\\scoring_{id}.txt\", all_events_with_header, delimiter='\\t',fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-ספט-23 19:51:11 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.8s finished\n",
      "23-ספט-23 19:51:34 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 19:51:38 | WARNING | Hypnogram is LONGER than data by 27.44 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.9s finished\n",
      "23-ספט-23 19:52:02 | WARNING | Hypnogram is LONGER than data by 27.44 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 19:52:05 | WARNING | Hypnogram is LONGER than data by 5.31 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.7s finished\n",
      "23-ספט-23 19:52:23 | WARNING | Hypnogram is LONGER than data by 5.31 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 19:52:26 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.8s finished\n",
      "23-ספט-23 19:52:49 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32_2</td>\n",
       "      <td>0.732361</td>\n",
       "      <td>0.870534</td>\n",
       "      <td>0.632042</td>\n",
       "      <td>53436</td>\n",
       "      <td>31109</td>\n",
       "      <td>7947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33_2</td>\n",
       "      <td>0.872374</td>\n",
       "      <td>0.822370</td>\n",
       "      <td>0.928853</td>\n",
       "      <td>343616</td>\n",
       "      <td>26320</td>\n",
       "      <td>74220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35_2</td>\n",
       "      <td>0.546022</td>\n",
       "      <td>0.545644</td>\n",
       "      <td>0.546402</td>\n",
       "      <td>14949</td>\n",
       "      <td>12410</td>\n",
       "      <td>12448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38_2</td>\n",
       "      <td>0.912288</td>\n",
       "      <td>0.941741</td>\n",
       "      <td>0.884620</td>\n",
       "      <td>354156</td>\n",
       "      <td>46192</td>\n",
       "      <td>21909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        f1    recall  precision      tp     fp     fn\n",
       "0  32_2  0.732361  0.870534   0.632042   53436  31109   7947\n",
       "1  33_2  0.872374  0.822370   0.928853  343616  26320  74220\n",
       "2  35_2  0.546022  0.545644   0.546402   14949  12410  12448\n",
       "3  38_2  0.912288  0.941741   0.884620  354156  46192  21909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comparison Spindles\n",
    "subs = [\"32\",\"33\",'35',\"38\"]\n",
    "\n",
    "comparisons_df = pd.DataFrame(columns=['id','f1','recall','precision', 'tp','fp','fn'])\n",
    "for sub in subs:\n",
    "    EEG_data, configu, datafile_scoring, exmp_scoring_upsampled = get_eeg_data(pkl_dir,sub,sleep_data_file_num)\n",
    "\n",
    "    res_kc = yasa.spindles_detect(EEG_data,sf=configu['sample_freq'], hypno = exmp_scoring_upsampled,\n",
    "                            verbose=False,\n",
    "                            freq_sp=(11, 16),\n",
    "                            thresh={\"rel_pow\": 0.2, \"corr\": 0.65, \"rms\": 1.5},\n",
    "                            include=[2, 3],ch_names=configu['electrodes_names'],\n",
    "                            multi_only=False,\n",
    "                            remove_outliers = False)\n",
    "    \n",
    "    manual_detection_filepath = f\"{pkl_dir}\\\\SS-YASA+Sleepstage_{sub}_{sleep_data_file_num}_MANUAL.txt\"\n",
    "    if os.path.exists(manual_detection_filepath):\n",
    "        comp_res = preform_ss_comparison_yasa(manual_detection_filepath,sub,sleep_data_file_num,res_kc.summary())\n",
    "        comparison = [f\"{sub}_{sleep_data_file_num}\",comp_res['f1'], comp_res['recall'], comp_res['precision'], np.size(comp_res['tp']), np.size(comp_res['fp']),np.size(comp_res['fn'])]\n",
    "        comparisons_df.loc[len(comparisons_df)] = comparison\n",
    "\n",
    "display(comparisons_df)\n",
    "# all_comp.to_csv('ss_comparisons.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-ספט-23 22:22:01 | WARNING | Hypnogram is LONGER than data by 27.44 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Documents\\githubProjects\\EventDetection\\eventDetection_2.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(auto_detection_filepath):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m     \u001b[39mfor\u001b[39;00m elec_i, elecd \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(kcomp_electrodes):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m         res \u001b[39m=\u001b[39m kc_detection(EEG_data[elec_i],configu[\u001b[39m'\u001b[39;49m\u001b[39msample_freq\u001b[39;49m\u001b[39m'\u001b[39;49m],[\u001b[39m2\u001b[39;49m],exmp_scoring_upsampled)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m         pos_kc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(res[\u001b[39m'\u001b[39m\u001b[39mkc_onset\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m/\u001b[39m configu[\u001b[39m'\u001b[39m\u001b[39msample_freq\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m         startTime_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pos_kc)\n",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Documents\\githubProjects\\EventDetection\\eventDetection_2.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m baseline_before_minima \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(filtered_eeg[sig_minima_samp_i\u001b[39m-\u001b[39m\u001b[39mint\u001b[39m(\u001b[39m1.5\u001b[39m\u001b[39m*\u001b[39msample_rate) : sig_minima_samp_i \u001b[39m-\u001b[39m \u001b[39mint\u001b[39m(sample_rate\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m)]) \u001b[39m# mean 1-2 sec before it\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mif\u001b[39;00m filtered_eeg[sig_minima_samp_i] \u001b[39m<\u001b[39m \u001b[39m2.5\u001b[39m\u001b[39m*\u001b[39m baseline_before_minima \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m sleepstages_upsampled[sig_minima_samp_i] \u001b[39min\u001b[39;00m included_sleepstages :\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m# Find the subsequent positive peak after the detected negative peak (within 1 second after the negative peak)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     maximas_samp_relative_i, maximas_popr \u001b[39m=\u001b[39m find_peaks(filtered_eeg[sig_minima_samp_i:], distance\u001b[39m=\u001b[39;49msample_rate, width\u001b[39m=\u001b[39;49m\u001b[39m0.15\u001b[39;49m\u001b[39m*\u001b[39;49msample_rate) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mif\u001b[39;00m maximas_samp_relative_i\u001b[39m.\u001b[39msize \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/githubProjects/EventDetection/eventDetection_2.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         maxima_samp_i \u001b[39m=\u001b[39m sig_minima_samp_i\u001b[39m+\u001b[39mmaximas_samp_relative_i[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\signal\\_peak_finding.py:936\u001b[0m, in \u001b[0;36mfind_peaks\u001b[1;34m(x, height, threshold, distance, prominence, width, wlen, rel_height, plateau_size)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mif\u001b[39;00m distance \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m distance \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`distance` must be greater or equal to 1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 936\u001b[0m peaks, left_edges, right_edges \u001b[39m=\u001b[39m _local_maxima_1d(x)\n\u001b[0;32m    937\u001b[0m properties \u001b[39m=\u001b[39m {}\n\u001b[0;32m    939\u001b[0m \u001b[39mif\u001b[39;00m plateau_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m     \u001b[39m# Evaluate plateau size\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# comparison K-complex\n",
    "subs = [\"33\",\"38\"]\n",
    "\n",
    "comparisons_df = pd.DataFrame(columns=['id','f1','recall','precision', 'tp','fp','fn','Positive', 'hitRate', 'falseDiscoveryRate'])\n",
    "for sub in subs:\n",
    "    file_id = f\"{sub}_{sleep_data_file_num}\"\n",
    "    EEG_data, configu, datafile_scoring, exmp_scoring_upsampled = get_eeg_data(pkl_dir,sub,sleep_data_file_num)\n",
    "    auto_kc_edfForm = np.vstack([header_edf,get_edfViewFormat_scoring(datafile_scoring)])\n",
    "    kcomp_electrodes = configu['electrodes_names'][~np.isin(configu['electrodes_names'], ['O1', 'O2'])]\n",
    "    auto_kc_edf_filepath = f\"{pkl_dir}\\\\KC+Sleepstage_{sub}_{sleep_data_file_num}.txt\"\n",
    "    if not os.path.exists(auto_kc_edf_filepath):\n",
    "        for elec_i, elecd in enumerate(kcomp_electrodes):\n",
    "            res_kc = kc_detection(EEG_data[elec_i],configu['sample_freq'],[2],exmp_scoring_upsampled)\n",
    "            pos_kc = np.array(res_kc['kc_onset']) / configu['sample_freq']\n",
    "\n",
    "            startTime_arr = np.array(pos_kc)\n",
    "            durations_arr = np.array(res_kc['durations'])\n",
    "            desc = [f\"kc@@{elecd}\" for x in startTime_arr]\n",
    "            auto_kc_edfForm_curr_electrode = np.array([startTime_arr ,durations_arr,desc],dtype=object).T ## onset (sec), duration,desc\n",
    "            auto_kc_edfForm = np.vstack([auto_kc_edfForm,auto_kc_edfForm_curr_electrode])\n",
    "        np.savetxt(auto_kc_edf_filepath, auto_kc_edfForm, delimiter='\\t',fmt='%s')\n",
    "\n",
    "    manual_detection_filepath = f\"{pkl_dir}\\\\KC+Sleepstage_{file_id}_MANUAL.txt\"\n",
    "    if os.path.exists(manual_detection_filepath):\n",
    "        all_kc_manu = np.loadtxt(manual_detection_filepath, delimiter=\"\\t\",dtype='object')\n",
    "\n",
    "        comp_res = preform_kc_comparison_yasa(manual_detection_filepath,sub,sleep_data_file_num,auto_kc_edf_filepath)\n",
    "        comparison = [f\"{sub}_{sleep_data_file_num}\",comp_res['f1'], comp_res['recall'], comp_res['precision'] \\\n",
    "                      , np.size(comp_res['tp']), np.size(comp_res['fp']),np.size(comp_res['fn'])    \\\n",
    "                      , np.shape(all_kc_manu)[0] \n",
    "                      , np.size(comp_res['tp']) / np.shape(all_kc_manu)[0] \\\n",
    "                      , np.size(comp_res['fp']) / (np.size(comp_res['tp'])+np.size(comp_res['fp'])) \\\n",
    "                      ]\n",
    "        comparisons_df.loc[len(comparisons_df)] = comparison\n",
    "        \n",
    "display(comparisons_df)\n",
    "# all_comp.to_csv('kc_comparisons.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and save detection for all subject "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-ספט-23 23:51:04 | WARNING | Hypnogram is LONGER than data by 0.46 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:51:04 | WARNING | Hypnogram is LONGER than data by 0.46 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.5s finished\n",
      "23-ספט-23 23:51:46 | WARNING | Hypnogram is LONGER than data by 3.38 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:51:46 | WARNING | Hypnogram is LONGER than data by 3.38 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.5s finished\n",
      "23-ספט-23 23:52:30 | WARNING | Hypnogram is LONGER than data by 4.19 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:52:30 | WARNING | Hypnogram is LONGER than data by 4.19 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.6s finished\n",
      "23-ספט-23 23:53:12 | WARNING | Hypnogram is LONGER than data by 21.70 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:53:12 | WARNING | Hypnogram is LONGER than data by 21.70 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.2s finished\n",
      "23-ספט-23 23:53:22 | WARNING | Hypnogram is LONGER than data by 4.30 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:53:22 | WARNING | Hypnogram is LONGER than data by 4.30 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.6s finished\n",
      "23-ספט-23 23:54:06 | WARNING | Hypnogram is LONGER than data by 27.44 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:54:06 | WARNING | Hypnogram is LONGER than data by 27.44 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.8s finished\n",
      "23-ספט-23 23:54:54 | WARNING | Hypnogram is LONGER than data by 26.90 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:54:54 | WARNING | Hypnogram is LONGER than data by 26.90 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.9s finished\n",
      "23-ספט-23 23:55:24 | WARNING | Hypnogram is LONGER than data by 24.74 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:55:24 | WARNING | Hypnogram is LONGER than data by 24.74 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.4s finished\n",
      "23-ספט-23 23:55:32 | WARNING | No spindle were found in channel O2.\n",
      "23-ספט-23 23:55:36 | WARNING | Hypnogram is LONGER than data by 29.36 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:55:36 | WARNING | Hypnogram is LONGER than data by 29.36 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.3s finished\n",
      "23-ספט-23 23:56:09 | WARNING | Hypnogram is LONGER than data by 5.31 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:56:09 | WARNING | Hypnogram is LONGER than data by 5.31 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.1s finished\n",
      "23-ספט-23 23:56:34 | WARNING | Hypnogram is LONGER than data by 14.24 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:56:34 | WARNING | Hypnogram is LONGER than data by 14.24 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.3s finished\n",
      "23-ספט-23 23:57:20 | WARNING | Hypnogram is LONGER than data by 23.22 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:57:20 | WARNING | Hypnogram is LONGER than data by 23.22 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.8s finished\n",
      "23-ספט-23 23:57:45 | WARNING | No spindle were found in channel O1.\n",
      "23-ספט-23 23:57:57 | WARNING | Hypnogram is LONGER than data by 6.27 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:57:57 | WARNING | Hypnogram is LONGER than data by 6.27 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    4.0s finished\n",
      "23-ספט-23 23:59:34 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:59:35 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    3.8s finished\n",
      "24-ספט-23 00:01:15 | WARNING | Hypnogram is LONGER than data by 5.58 seconds. Cropping hypnogram to match data.size.\n",
      "24-ספט-23 00:01:15 | WARNING | Hypnogram is LONGER than data by 5.58 seconds. Cropping hypnogram to match data.size.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "# SS  - run and save\n",
    "subs = [\"30\",\"33\",'35',\"38\"]\n",
    "for sub in subs:\n",
    "    ss_df_curr_sub = pd.DataFrame();\n",
    "    for filenum in range(1,6):\n",
    "        file_id = f\"{sub}_{filenum}\"\n",
    "        if not get_eeg_data(pkl_dir,sub,filenum): continue\n",
    "        EEG_data, configu, datafile_scoring, exmp_scoring_upsampled = get_eeg_data(pkl_dir,sub,filenum)\n",
    "        auto_ss_edfForm = np.vstack([header_edf,get_edfViewFormat_scoring(datafile_scoring)])\n",
    "        auto_ss_edf_filepath = f\"{pkl_dir}\\\\SS-YASA+Sleepstage_{file_id}.txt\"\n",
    "        auto_detection_ss_filepath_csv =f'{pkl_dir}//sub-{sub}_Spindles.csv'\n",
    "\n",
    "        # create csv - spindles\n",
    "        res_ss = yasa.spindles_detect(EEG_data,sf=configu['sample_freq'], hypno = exmp_scoring_upsampled,\n",
    "            verbose=False,\n",
    "            freq_sp=(11, 16),\n",
    "            thresh={\"rel_pow\": 0.2, \"corr\": 0.65, \"rms\": 1.5},\n",
    "            include=[2, 3],ch_names=configu['electrodes_names'],\n",
    "            multi_only=False,\n",
    "            remove_outliers = False)\n",
    "        ss_summary = res_ss.summary()\n",
    "        \n",
    "        filtered, filtered_moreThan1 = group_events(res_ss.summary(), 'Start','End','RelPower',\"Channel\")\n",
    "        \n",
    "        # create edf event \n",
    "        startTime_arr = np.array(ss_summary['Start'])\n",
    "        endTime_arr = np.array(ss_summary['End'])\n",
    "        duration_arr = endTime_arr - startTime_arr\n",
    "        electd_arr_per_ss = np.array(ss_summary['Channel'])\n",
    "        desc = [f\"ss-YASA@@{electd_arr}\" for electd_arr in electd_arr_per_ss]\n",
    "        auto_ss_edfForm_curr_electrode = np.array([startTime_arr ,durations_arr,desc],dtype=object).T ## onset (sec), duration,desc\n",
    "        auto_ss_edfForm = np.vstack([auto_ss_edfForm,auto_ss_edfForm_curr_electrode])\n",
    "        np.savetxt(auto_ss_edf_filepath, auto_ss_edfForm, delimiter='\\t',fmt='%s')\n",
    "\n",
    "\n",
    "        new_df = pd.DataFrame(ss_summary)\n",
    "        new_df['sub'] = sub\n",
    "        new_df['subfile'] = filenum\n",
    "        new_df['eventType'] = 'Spindles'\n",
    "        if ss_df_curr_sub.empty:\n",
    "            ss_df_curr_sub= new_df\n",
    "        else:   \n",
    "            ss_df_curr_sub = pd.concat([ss_df_curr_sub,new_df])\n",
    "\n",
    "    # save csv\n",
    "    if(ss_df_curr_sub.size>0):\n",
    "        ss_df_curr_sub.to_csv(auto_detection_ss_filepath_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-ספט-23 22:52:54 | WARNING | Hypnogram is LONGER than data by 0.46 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:52:54 | WARNING | Hypnogram is LONGER than data by 0.46 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:54:26 | WARNING | Hypnogram is LONGER than data by 3.38 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:54:26 | WARNING | Hypnogram is LONGER than data by 3.38 seconds. Cropping hypnogram to match data.size.\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "23-ספט-23 22:56:09 | WARNING | Hypnogram is LONGER than data by 4.19 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:56:09 | WARNING | Hypnogram is LONGER than data by 4.19 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:57:51 | WARNING | Hypnogram is LONGER than data by 21.70 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:57:51 | WARNING | Hypnogram is LONGER than data by 21.70 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:58:07 | WARNING | Hypnogram is LONGER than data by 4.30 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:58:07 | WARNING | Hypnogram is LONGER than data by 4.30 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:59:44 | WARNING | Hypnogram is LONGER than data by 27.44 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 22:59:44 | WARNING | Hypnogram is LONGER than data by 27.44 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:02:04 | WARNING | Hypnogram is LONGER than data by 26.90 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:02:04 | WARNING | Hypnogram is LONGER than data by 26.90 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:02:47 | WARNING | Hypnogram is LONGER than data by 24.74 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:02:47 | WARNING | Hypnogram is LONGER than data by 24.74 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:02:59 | WARNING | Hypnogram is LONGER than data by 29.36 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:02:59 | WARNING | Hypnogram is LONGER than data by 29.36 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:03:43 | WARNING | Hypnogram is LONGER than data by 5.31 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:03:44 | WARNING | Hypnogram is LONGER than data by 5.31 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:04:15 | WARNING | Hypnogram is LONGER than data by 14.24 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:04:16 | WARNING | Hypnogram is LONGER than data by 14.24 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:05:17 | WARNING | Hypnogram is LONGER than data by 23.22 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:05:17 | WARNING | Hypnogram is LONGER than data by 23.22 seconds. Cropping hypnogram to match data.size.\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "23-ספט-23 23:05:32 | WARNING | Hypnogram is LONGER than data by 6.27 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:05:32 | WARNING | Hypnogram is LONGER than data by 6.27 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:08:24 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:08:25 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "23-ספט-23 23:10:38 | WARNING | Hypnogram is LONGER than data by 5.58 seconds. Cropping hypnogram to match data.size.\n",
      "23-ספט-23 23:10:38 | WARNING | Hypnogram is LONGER than data by 5.58 seconds. Cropping hypnogram to match data.size.\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# KC  - run and save\n",
    "subs = [\"30\",\"33\",'35',\"38\"]\n",
    "for sub in subs:\n",
    "    kc_df_curr_sub = pd.DataFrame();\n",
    "    for filenum in range(1,6):\n",
    "        file_id = f\"{sub}_{filenum}\"\n",
    "        if not get_eeg_data(pkl_dir,sub,filenum): continue;\n",
    "        EEG_data, configu, datafile_scoring, exmp_scoring_upsampled = get_eeg_data(pkl_dir,sub,filenum)\n",
    "        auto_kc_edfForm = np.vstack([header_edf,get_edfViewFormat_scoring(datafile_scoring)])\n",
    "        kcomp_electrodes = configu['electrodes_names'][~np.isin(configu['electrodes_names'], ['O1', 'O2'])]\n",
    "        auto_kc_edf_filepath = f\"{pkl_dir}\\\\KC+Sleepstage_{sub}_{filenum}.txt\"\n",
    "        auto_detection_kc_filepath_csv =f'{pkl_dir}//sub-{sub}_KComp.csv'\n",
    "        if not os.path.exists(auto_kc_edf_filepath) or not os.path.exists(auto_detection_kc_filepath_csv):\n",
    "            for elec_i, elecd in enumerate(kcomp_electrodes):\n",
    "                res_kc = kc_detection(EEG_data[elec_i],configu['sample_freq'],[2],exmp_scoring_upsampled)\n",
    "                pos_kc = np.array(res_kc['kc_onset']) / configu['sample_freq']\n",
    "\n",
    "                # create edf event \n",
    "                startTime_arr = np.array(pos_kc)\n",
    "                durations_arr = np.array(res_kc['durations'])\n",
    "                desc = [f\"kc@@{elecd}\" for x in startTime_arr]\n",
    "                auto_kc_edfForm_curr_electrode = np.array([startTime_arr ,durations_arr,desc],dtype=object).T ## onset (sec), duration,desc\n",
    "                auto_kc_edfForm = np.vstack([auto_kc_edfForm,auto_kc_edfForm_curr_electrode])\n",
    "                \n",
    "                # create csv - kcomp\n",
    "                new_df = pd.DataFrame(res_kc)\n",
    "                new_df['sub'] = sub\n",
    "                new_df['subfile'] = filenum\n",
    "                new_df['eventType'] = 'KComp'\n",
    "                new_df['electrode'] = elecd\n",
    "                if kc_df_curr_sub.empty:\n",
    "                    kc_df_curr_sub= new_df\n",
    "                else:   \n",
    "                    kc_df_curr_sub = pd.concat([kc_df_curr_sub,new_df])\n",
    "\n",
    "            # save csv\n",
    "            if(kc_df_curr_sub.size>0):\n",
    "                filtered, filtered_moreThan1 = group_events(kc_df_curr_sub, \"kc_onset\", \"kc_end\",'kc_peak_difference','electrode')\n",
    "                filtered.to_csv(auto_detection_kc_filepath_csv)\n",
    "\n",
    "            # save edf\n",
    "            np.savetxt(auto_kc_edf_filepath, auto_kc_edfForm, delimiter='\\t',fmt='%s')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCHIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw detection\n",
    "sw = yasa.sw_detect(datafile_data,sf=configu['sample_freq'], hypno = exmp_scoring_upsampled,\n",
    "                          include=[2, 3],ch_names=configu['electrodes_names'])\n",
    "sw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison Spindles - old detection params\n",
    "subs = [\"32\",\"33\",'35',\"38\"]\n",
    "\n",
    "comparisons_df = pd.DataFrame(columns=['id','Positive','TruePos','FalsePos', 'hitRate','falseDiscoveryRate'])\n",
    "for sub in subs:\n",
    "    EEG_data, configu, datafile_scoring, exmp_scoring_upsampled = get_eeg_data(pkl_dir,sub,sleep_data_file_num)\n",
    "\n",
    "    res_kc = yasa.spindles_detect(EEG_data,sf=configu['sample_freq'], hypno = exmp_scoring_upsampled,\n",
    "                            verbose=False,\n",
    "                            freq_sp=(11, 16),\n",
    "                            thresh={\"rel_pow\": 0.2, \"corr\": 0.65, \"rms\": 1.5},\n",
    "                            include=[2, 3],ch_names=configu['electrodes_names'],\n",
    "                            multi_only=True,\n",
    "                            remove_outliers = True)\n",
    "    # print(sp)\n",
    "    # print(sp.summary())\n",
    "    # sp.plot_average(center='Peak',time_before = 1,time_after = 1)\n",
    "    # plt.show()\n",
    "    #%matplotlib widget\n",
    "    #sp.plot_detection()\n",
    "\n",
    "    sp_summary = res_kc.summary()\n",
    "    file_id = f\"{sub}_{sleep_data_file_num}\"\n",
    "\n",
    "    startTime_arr = np.array(sp_summary['Start'])\n",
    "    endTime_arr = np.array(sp_summary['End'])\n",
    "    duration_arr = endTime_arr - startTime_arr\n",
    "    electd_arr_per_ss = np.array(sp_summary['Channel'])\n",
    "    desc = [f\"ss-YASA@@{electd_arr}\" for electd_arr in electd_arr_per_ss]\n",
    "    auto_ss_edfForm = np.array([startTime_arr ,duration_arr,desc],dtype=object).T ## onset (sec), duration,desc\n",
    "\n",
    "    manual_detection_filepath = f\"{pkl_dir}\\\\SS-YASA+Sleepstage_{file_id}_MANUAL.txt\"\n",
    "    if os.path.exists(manual_detection_filepath):\n",
    "        all_event_manu = np.loadtxt(manual_detection_filepath, delimiter=\"\\t\",dtype='object')\n",
    "\n",
    "        comparison = preform_event_comparison(all_event_manu,auto_ss_edfForm,file_id)\n",
    "        comparisons_df.loc[len(comparisons_df)] = comparison\n",
    "        \n",
    "display(comparisons_df)\n",
    "# all_comp.to_csv('ss_comparisons.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f544ce1a915a9875fad91c894e2c0bcad4b7a79945aa6027ef3ad27810072aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
