{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.stats\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "import gc\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "from os.path import exists\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne import create_info\n",
    "from IPython.utils import io\n",
    "import yasa\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matlab\n",
    "import matlab.engine\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def overlap(a, b):\n",
    "    return a[1] >= b[0] and a[0] <= b[1]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = \"C:\\\\Users\\\\User\\\\Cloud-Drive\\\\BigFiles\\\\OmissionExpOutput\\\\\\imported_eventDetectionChan\\\\filter0.35\"\n",
    "import_type = \"eventDetectionChan\"\n",
    "output_dir_name = 'eventDetection\\\\done_on_imported'\n",
    "import_path = f'{pkl_dir}\\\\{import_type}.pkl'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Nir&Andrillon Spindle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrode_column_name = 'electrode'\n",
    "header = np.array(['Onset',\"Duration\",\"Annotation\"])\n",
    "\n",
    "\n",
    "def detect_sw_AndrillonNir(file_ids,output_key,electrodes_names):\n",
    "    andriNir_code_dir = os.getcwd()\n",
    "    andriNir_output_dir = f\"{configu['outputs_dir_path']}\\\\{output_dir_name}\\\\Andrillon_Nir\"\n",
    "    andriNir_aux_output_dir = f\"{andriNir_output_dir}\\\\aux_mats\"\n",
    "\n",
    "    if os.path.exists(andriNir_output_dir):\n",
    "        shutil.rmtree(andriNir_output_dir)\n",
    "    os.mkdir(andriNir_output_dir)\n",
    "    os.mkdir(andriNir_aux_output_dir)\n",
    "\n",
    "    sw_output_columns = ['wavest' ,'wavend', 'mdpt', 'poszx', 'period/SR' ,'abs(b)', 'bx', 'c' ,'cx' ,'maxb2c', 'n1', 'n1x', 'nEnd', 'nEndx' ,'p1', 'p1x' ,'meanAmp', 'nump', 'nperiod/SR', 'p2p', 'mxdn', 'mxup' ,'currentStage']\n",
    "\n",
    "    for id in file_ids:\n",
    "        datafile_data = allsubsdata_perFile[id]['data'] ## shape (electrode, time)\n",
    "        datafile_scoring = allsubsdata_perFile[id]['scoring'] ## shape (time/sampling/30)\n",
    "        scoring_upsampled = yasa.hypno_upsample_to_data(datafile_scoring, 1/30, datafile_data, sf_data=configu['sample_freq'], verbose=True)\n",
    "        sw_allElectrodes = pd.DataFrame()\n",
    "\n",
    "        for electd_i, electrode_name_eventDetect in enumerate(electrodes_names):\n",
    "            curr_electrode_num = np.where(configu['electrodes_names'] == electrode_name_eventDetect)[0][0]\n",
    "\n",
    "            ## create aux files to use in MATLAB\n",
    "            datafile_1elect_eeg = datafile_data[curr_electrode_num,:]\n",
    "            if 2 not in datafile_scoring or 3 not in datafile_scoring:\n",
    "                continue\n",
    "            \n",
    "            mat_to_save = {'datafile_data': datafile_1elect_eeg, 'scoring_upsampled': scoring_upsampled, 'sample_freq': configu['sample_freq'], 'electrode_name':electrode_name_eventDetect}\n",
    "            scipy.io.savemat(f\"{andriNir_aux_output_dir}\\\\{allsubsdata_perFile[id]['subnum']}_{allsubsdata_perFile[id]['filenum']}_{electrode_name_eventDetect}AndScoring.mat\",mat_to_save)\n",
    "\n",
    "            ## run Andrillon & Nir SW detection over all subjects files\n",
    "            eng = matlab.engine.start_matlab()\n",
    "            eng.cd(andriNir_code_dir, nargout=0)\n",
    "            out = eng.batch_useAndrillonNirSWDetection(andriNir_aux_output_dir, andriNir_output_dir,nargout=0)\n",
    "            eng.quit()\n",
    "\n",
    "            ## add the SW data to the main subject dictionary\n",
    "            try: \n",
    "                sw_file_name = f\"{andriNir_output_dir}\\\\{output_key}_{allsubsdata_perFile[id]['subnum']}_{allsubsdata_perFile[id]['filenum']}_{electrode_name_eventDetect}AndScoring.mat\"\n",
    "                matlabImport = scipy.io.loadmat(sw_file_name, simplify_cells=True)\n",
    "            except Exception: \n",
    "                print(f\"Error importing spindles sub file at: {allsubsdata_perFile[id]['subnum']}_{allsubsdata_perFile[id]['filenum']}\")\n",
    "                continue\n",
    "\n",
    "            sw = matlabImport['allWaves']\n",
    "            if np.size(np.shape(sw)) == 1: \n",
    "                temp = np.zeros((1,np.size(sw)),dtype=object)\n",
    "                temp[0] = sw\n",
    "                sw = temp\n",
    "            if np.size(sw) >0 :\n",
    "                df = pd.DataFrame(np.double(sw))\n",
    "                df.columns = sw_output_columns\n",
    "                tile_electrode = np.tile(f\"{electrode_name_eventDetect}\", sw.shape[0])[None].T\n",
    "                df[electrode_column_name] = tile_electrode\n",
    "                \n",
    "                allsubsdata_perFile[id][f\"{output_key}@@{electrode_name_eventDetect}\"] = df\n",
    "                if electd_i ==0: sw_allElectrodes =  df\n",
    "                else:  sw_allElectrodes = pd.concat([sw_allElectrodes,df])\n",
    "    \n",
    "        if not sw_allElectrodes.empty:\n",
    "            allsubsdata_perFile[id][output_key]  = sw_allElectrodes\n",
    "    shutil.rmtree(andriNir_aux_output_dir)\n",
    "\n",
    "def detect_ss_AndrillonNir(file_ids,minMax_sd_ver,output_key,electrodes_names):\n",
    "    andriNir_code_dir = os.getcwd()\n",
    "    andriNir_output_dir = f\"{configu['outputs_dir_path']}\\\\{output_dir_name}\\\\Andrillon_Nir\"\n",
    "    andriNir_aux_output_dir = f\"{andriNir_output_dir}\\\\aux_mats\"\n",
    "\n",
    "    if os.path.exists(andriNir_output_dir):\n",
    "        shutil.rmtree(andriNir_output_dir)\n",
    "    os.mkdir(andriNir_output_dir)\n",
    "    os.mkdir(andriNir_aux_output_dir)\n",
    "\n",
    "    spindles_output_columns =  ['spindleStartTime', 'spindleEndTime', 'peakTime', 'peakEnergy', 'peakEnergyNorm', 'freqSpindle', 'spindleDuration/SR', 'PowerSP', 'PowerAlpha', 'currentStage']\n",
    "\n",
    "    for id in file_ids:\n",
    "        datafile_data = allsubsdata_perFile[id]['data'] ## shape (electrode, time)\n",
    "        datafile_scoring = allsubsdata_perFile[id]['scoring'] ## shape (time/sampling/30)\n",
    "        scoring_upsampled = yasa.hypno_upsample_to_data(datafile_scoring, 1/30, datafile_data, sf_data=configu['sample_freq'], verbose=True)\n",
    "        ss_allElectrodes = pd.DataFrame()\n",
    "\n",
    "        for electd_i, electrode_name_eventDetect in enumerate(electrodes_names):\n",
    "            curr_electrode_num = np.where(configu['electrodes_names'] == electrode_name_eventDetect)[0][0]\n",
    "\n",
    "            ## create aux files to use in MATLAB\n",
    "            datafile_1elect_eeg = datafile_data[curr_electrode_num,:]\n",
    "            if 2 not in datafile_scoring or 3 not in datafile_scoring:\n",
    "                continue\n",
    "            \n",
    "            DetectionThreshold = minMax_sd_ver[0]\n",
    "            RejectThreshold = minMax_sd_ver[1]\n",
    "            StartEndThreshold = minMax_sd_ver[2]\n",
    "            mat_to_save = {'datafile_data': datafile_1elect_eeg, 'scoring_upsampled': scoring_upsampled, 'sample_freq': configu['sample_freq'], 'electrode_name':electrode_name_eventDetect, 'DetectionThreshold':DetectionThreshold,'RejectThreshold':RejectThreshold, 'StartEndThreshold':StartEndThreshold}\n",
    "            scipy.io.savemat(f\"{andriNir_aux_output_dir}\\\\{allsubsdata_perFile[id]['subnum']}_{allsubsdata_perFile[id]['filenum']}_{electrode_name_eventDetect}AndScoring.mat\",mat_to_save)\n",
    "\n",
    "            ## run Andrillon & Nir SS detection over all subjects files\n",
    "            eng = matlab.engine.start_matlab()\n",
    "            eng.cd(andriNir_code_dir, nargout=0)\n",
    "            out = eng.batch_useAndrillonNirSSDetection(andriNir_aux_output_dir, andriNir_output_dir,nargout=0)\n",
    "            eng.quit()\n",
    "\n",
    "            ## add the spindles data to the main subject dictionary\n",
    "            try: \n",
    "                spindles_file_name = f\"{andriNir_output_dir}\\\\SS_AN_{allsubsdata_perFile[id]['subnum']}_{allsubsdata_perFile[id]['filenum']}_{electrode_name_eventDetect}AndScoring.mat\"\n",
    "                matlabImport = scipy.io.loadmat(spindles_file_name, simplify_cells=True)\n",
    "            except Exception: \n",
    "                print(f\"Error importing spindles sub file at: {allsubsdata_perFile[id]['subnum']}_{allsubsdata_perFile[id]['filenum']}\")\n",
    "                continue\n",
    "\n",
    "            ss = matlabImport['spindles']\n",
    "            if np.size(np.shape(ss)) == 1: \n",
    "                temp = np.zeros((1,np.size(ss)),dtype=object)\n",
    "                temp[0] = ss\n",
    "                ss = temp\n",
    "            if np.size(ss) >0 :\n",
    "                df = pd.DataFrame(np.double(ss))\n",
    "                df.columns = spindles_output_columns\n",
    "                tile_electrode = np.tile(f\"{electrode_name_eventDetect}\", ss.shape[0])[None].T\n",
    "                df[electrode_column_name] = tile_electrode\n",
    "                \n",
    "                allsubsdata_perFile[id][f'{output_key}@@{electrode_name_eventDetect}'] = df\n",
    "                if electd_i ==0: ss_allElectrodes =  df\n",
    "                else:  ss_allElectrodes = pd.concat([ss_allElectrodes,df])\n",
    "\n",
    "            # sw = matlabImport['allWaves']\n",
    "            # if np.size(sw) >0 :\n",
    "            #     tile_electrode = np.tile(f\"{electrode_name_eventDetect}\", sw.shape[0])[None].T\n",
    "            #     sw = np.hstack([sw, tile_electrode])\n",
    "            #     allsubsdata_perFile[id][f'SW_algo-AN@@{electrode_name_eventDetect}'] = np.asarray(sw,dtype=object)  \n",
    "            #     sw_allElectrodes = np.concatenate((sw_allElectrodes,sw))\n",
    "    \n",
    "        if not ss_allElectrodes.empty:\n",
    "            #print(f\"sub:{id}, thresh:{matlabImport['minMax_SD_threshold']},  before {len(ss_allElectrodes)}\")\n",
    "            allsubsdata_perFile[id][output_key]  = ss_allElectrodes\n",
    "            #allsubsdata_perFile[id][f'SW_algo-AN_all']  = sw_allElectrodes\n",
    "\n",
    "    minmax_sd_name =  matlabImport['minMax_SD_threshold']\n",
    "    shutil.rmtree(andriNir_aux_output_dir)\n",
    "    return minmax_sd_name\n",
    "def filter_sleep_stages(file_ids,event_key_to_use,after_sleepStage_exclution_key, sleepstages):\n",
    "    for id in file_ids:\n",
    "        if event_key_to_use not in allsubsdata_perFile[id]: continue\n",
    "        event_allElectrodes = allsubsdata_perFile[id][event_key_to_use]\n",
    "        \n",
    "        event_filtered_sleepstages = pd.DataFrame([], columns=event_allElectrodes.columns)\n",
    "        for sleepstage in sleepstages:\n",
    "            event_filtered_sleepstages = pd.concat([event_filtered_sleepstages , event_allElectrodes.loc[(event_allElectrodes['currentStage'] == sleepstage)]])\n",
    "\n",
    "        if len(event_filtered_sleepstages) == 0:  print(f\"sub:{id} - no events in sleepstages{sleepstages}\")\n",
    "        else: print(f\"sub:{id}, before exclude sleep stages:{len(event_allElectrodes)}, after:{len(event_filtered_sleepstages)}\")\n",
    "        \n",
    "        allsubsdata_perFile[id][after_sleepStage_exclution_key] = event_filtered_sleepstages\n",
    "\n",
    "def filter_waveCriteria(file_ids,event_key_to_use,after_sleepStage_exclution_key):\n",
    "    for id in file_ids:\n",
    "        if event_key_to_use not in allsubsdata_perFile[id]: continue\n",
    "        event_allElectrodes = allsubsdata_perFile[id][event_key_to_use]\n",
    "        event_filtered_waveCrit = pd.DataFrame([], columns=event_allElectrodes.columns)\n",
    "\n",
    "        event_filtered_waveCrit = event_allElectrodes[(event_allElectrodes['maxb2c'] > 75)]\n",
    "\n",
    "        if len(event_filtered_waveCrit) == 0:  print(f\"sub:{id} - no sw with criteria\")\n",
    "        else: print(f\"sub:{id}, before wave criteria sleep stages:{len(event_allElectrodes)}, after:{len(event_filtered_waveCrit)}\")\n",
    "        \n",
    "        allsubsdata_perFile[id][after_sleepStage_exclution_key] = event_filtered_waveCrit\n",
    "def group_spindles(ss_key_to_use, uniqeElctds_ss_key, uniqeElctd_ss_key):\n",
    "    ## create a spindle array, where each spindle occour once and attribued to the electrode where the spindle was the most powerful\n",
    "    for id in allsubsdata_perFile:\n",
    "        if ss_key_to_use not in allsubsdata_perFile[id]:  continue\n",
    "        filterd_events_allElectrodes = allsubsdata_perFile[id][ss_key_to_use].copy(deep=True)\n",
    "        \n",
    "        filterd_events_allElectrodes.sort_values(by=['spindleStartTime'],inplace=True) \n",
    "        filterd_events_allElectrodes.reset_index(drop=True, inplace=True)\n",
    "        deleted = filterd_events_allElectrodes.copy(deep=True)\n",
    "        filtered = pd.DataFrame([], columns = deleted.columns)\n",
    "        filtered_moreThan1 = pd.DataFrame([], columns = deleted.columns)\n",
    "        simultan = pd.DataFrame([], columns = deleted.columns)\n",
    "\n",
    "        while len(deleted)>0:\n",
    "            if len(simultan)==0:\n",
    "                simultan = pd.concat([simultan, deleted.iloc[[0]]])\n",
    "                deleted.drop(deleted.index[0], axis=0, inplace=True)\n",
    "                still_overlap = True\n",
    "            else:\n",
    "                while still_overlap == True and len(deleted)>0:\n",
    "                    still_overlap = False\n",
    "                    simultan.reset_index(drop=True, inplace=True) # make sure indexes pair with number of rows\n",
    "\n",
    "                    ## check now_overlap_all_in_simultan:\n",
    "                    for index, simultan_row in simultan.iterrows():\n",
    "                        simultan_0 = simultan_row['spindleStartTime']\n",
    "                        simultan_1 = simultan_row['spindleEndTime']\n",
    "                        deleted_0 = deleted.iloc[0]['spindleStartTime']\n",
    "                        deleted_1 = deleted.iloc[0]['spindleEndTime']\n",
    "                        if overlap([simultan_0,simultan_1],[deleted_0,deleted_1]):\n",
    "                            simultan = pd.concat([simultan, deleted.iloc[[0]]])\n",
    "                            deleted.drop(deleted.index[0], axis=0, inplace=True)\n",
    "                            still_overlap = True\n",
    "                            break\n",
    "                    if still_overlap: continue\n",
    "                    else:\n",
    "                        ## check max ps and add to filt\n",
    "                        # if len(simultan)>1:\n",
    "                        #     print('hu')\n",
    "                        simultan.sort_values(by=['PowerSP'],ascending=False,inplace=True)\n",
    "                        row_df = simultan.iloc[[0]]\n",
    "                        row_df.iat[0, row_df.columns.get_loc(electrode_column_name)] = np.array(simultan[electrode_column_name])\n",
    "                        filtered = pd.concat([filtered,row_df])\n",
    "                        if len(simultan) > 1: filtered_moreThan1 = pd.concat([filtered_moreThan1,row_df])\n",
    "                        simultan = pd.DataFrame([], columns = deleted.columns)                    \n",
    "            \n",
    "        filtered.reset_index(drop=True, inplace=True) # make sure indexes pair with number of rows\n",
    "        filtered_moreThan1.reset_index(drop=True, inplace=True) # make sure indexes pair with number of rows\n",
    "        allsubsdata_perFile[id][uniqeElctd_ss_key] = filtered   \n",
    "        allsubsdata_perFile[id][uniqeElctds_ss_key] = filtered_moreThan1   \n",
    "        print(f\"sub:{id}, before filt:{np.shape(allsubsdata_perFile[id][ss_key_to_use])[0]}, after:{np.shape(allsubsdata_perFile[id][uniqeElctd_ss_key])[0]}, after>1: after:{np.shape(allsubsdata_perFile[id][uniqeElctds_ss_key])[0]}\")\n",
    "\n",
    "def edfViewFormat_scoring_dict(score):\n",
    "    if score == 0:\n",
    "        return 'W'\n",
    "    elif score ==1:\n",
    "        return 'N1'\n",
    "    elif score ==2:\n",
    "        return 'N2'\n",
    "    elif score ==3:\n",
    "        return 'N3'\n",
    "    elif score ==4:\n",
    "        return 'TREM'\n",
    "    elif score ==5:\n",
    "        return 'PREM'\n",
    "    elif score ==6:\n",
    "        return 'MOVE'\n",
    "    elif score ==7:\n",
    "        return 'ARTIFACT'\n",
    "    else:\n",
    "        Exception('no such score')\n",
    "def add_edfViewFormat_scoring(key_edfScoringFormat):\n",
    "    for id in allsubsdata_perFile:\n",
    "        curr_file_scoring = allsubsdata_perFile[id]['scoring']\n",
    "        new_format_score = np.zeros((len(curr_file_scoring),3), dtype=object)\n",
    "        for ind, score in enumerate(curr_file_scoring):\n",
    "                new_format_score[ind,:] = [30*ind,30,edfViewFormat_scoring_dict(score)] ## onset (sec), duration, desc\n",
    "\n",
    "        allsubsdata_perFile[id][key_edfScoringFormat] = new_format_score\n",
    "def add_edfViewFormat_ss(file_ids,event_key_for_save, SS_efdViewFormat_key):\n",
    "        for id in file_ids:\n",
    "            if event_key_for_save not in allsubsdata_perFile[id]:\n",
    "                    #print(f\"no {event_key_for_save} for sub {id}\")\n",
    "                    continue\n",
    "            ss_df = allsubsdata_perFile[id][event_key_for_save]\n",
    "            startTime_arr = np.array(ss_df['spindleStartTime']) / np.double(configu['sample_freq'])\n",
    "            endTime_arr = np.array(ss_df['spindleEndTime']) / np.double(configu['sample_freq'])\n",
    "            duration_arr = endTime_arr - startTime_arr\n",
    "            electd_arr_per_ss = np.array(ss_df[electrode_column_name])\n",
    "            desc = [f\"SS@@{electd_arr[0]}\" for electd_arr in electd_arr_per_ss] ## NOTICE: this will work only if the electrode column consists of values which are arrays\n",
    "            new_format_ss = np.array([startTime_arr,duration_arr,desc]).T ## onset (sec), duration,desc\n",
    "            allsubsdata_perFile[id][SS_efdViewFormat_key] = new_format_ss\n",
    "def add_edfViewFormat_sw(file_ids,event_key_for_save, SW_efdViewFormat_key):\n",
    "        for id in file_ids:\n",
    "            if event_key_for_save not in allsubsdata_perFile[id]:\n",
    "                    #print(f\"no {event_key_for_save} for sub {id}\")\n",
    "                    continue\n",
    "            sw_df = allsubsdata_perFile[id][event_key_for_save]\n",
    "    \n",
    "            startTime_arr = np.array(sw_df['wavest'])\n",
    "            endTime_arr = np.array(sw_df['wavend'])\n",
    "            duration_arr = (endTime_arr - startTime_arr)  / np.double(configu['sample_freq'])\n",
    "            electd_arr_per_sw = np.array(sw_df[electrode_column_name])\n",
    "            desc = [f\"SW@@{electd_arr}\" for electd_arr in electd_arr_per_sw]\n",
    "            new_format_sw = np.array([startTime_arr / np.double(configu['sample_freq']) ,duration_arr,desc]).T ## onset (sec), duration,desc\n",
    "\n",
    "            allsubsdata_perFile[id][SW_efdViewFormat_key] = new_format_sw\n",
    "\n",
    "def save_eventsSepratelyForComparison_edfViewFormat(file_ids,events_types_to_compare,edfViewFormat_output_dir):\n",
    "    # Save events (scoring and ss) per file, in a format suitable for EDF_viewer\n",
    "    for id in file_ids:\n",
    "        for event_type in events_types_to_compare:\n",
    "            filename = f\"{allsubsdata_perFile[id]['subnum']}_{allsubsdata_perFile[id]['filenum']}_events\"\n",
    "            all_events_with_header = np.asarray([header],dtype=object)\n",
    "            events_type_found = [ v for k, v in allsubsdata_perFile[id].items() if ((event_type in k) and (edfviewFormatSuffix in k))]\n",
    "            if np.size(events_type_found) == 0: continue\n",
    "            for events_found in events_type_found:\n",
    "                    for event_found in events_found:\n",
    "                            all_events_with_header = np.concatenate((all_events_with_header,[event_found]),dtype=object)\n",
    "            np.savetxt(f\"{edfViewFormat_output_dir}\\\\{event_type}_{filename}.txt\", all_events_with_header, delimiter='\\t',fmt='%s')\n",
    "    \n",
    "# Save events (scoring and ss) per file, in a format suitable for EDF_viewer\n",
    "def save_eventsAllTogether_edfViewFormat(events_types_for_save,edfViewFormat_output_dir):\n",
    "        for id in file_ids:\n",
    "            filename = f\"{allsubsdata_perFile[id]['subnum']}_{allsubsdata_perFile[id]['filenum']}_events\"\n",
    "            all_events_with_header = np.asarray([header],dtype=object)\n",
    "            for event_type in events_types_for_save:\n",
    "                events_type_found = [ v for k, v in allsubsdata_perFile[id].items() if (event_type in k) and (edfviewFormatSuffix in k)]\n",
    "                if np.size(events_type_found) == 0: continue\n",
    "                for events_found in events_type_found:\n",
    "                        for event_found in events_found:\n",
    "                                all_events_with_header = np.concatenate((all_events_with_header,[event_found]),dtype=object)\n",
    "            np.savetxt(f\"{edfViewFormat_output_dir}\\\\allEvents_{filename}.txt\", all_events_with_header, delimiter='\\t',fmt='%s')\n",
    "\n",
    "def preform_minmaxSD_comparison(events_types_to_compare,file_ids,minMax_sd_vers):\n",
    "    all_comparisons = pd.DataFrame(columns=['id','eventType','minmax_ver','Positive','TruePos','FalsePos', 'hitRate','falseDiscoveryRate'])\n",
    "    for id in file_ids:\n",
    "        for ver in minMax_sd_vers:\n",
    "            for event_type in events_types_to_compare:\n",
    "                dir_auto_ = f\"{edfViewFormat_events_output_dir}\\\\{ver}\"\n",
    "                manual_detection_filename = f\"{edfViewFormat_events_manual_dir}\\\\sub{id.split('_')[0]}_sleep{id.split('_')[1]}_imported_eventDetectionChan_annotations.txt\"\n",
    "                auto_detection_filename = f\"{dir_auto_}\\\\{event_type}_{id}_events.txt\"\n",
    "                ## get the array of before manual scanning\n",
    "                if os.path.exists(auto_detection_filename) and os.path.exists(manual_detection_filename):\n",
    "                    all_ss_auto = np.loadtxt(auto_detection_filename, delimiter=\"\\t\",dtype='object')\n",
    "                    all_ss_auto = np.delete(all_ss_auto, np.where(all_ss_auto[:, 2] == \"Annotation\")[0], axis=0)\n",
    "                    all_ss_auto[:,[0,1]] = [np.double(x) for x in all_ss_auto[:,[0,1]]]\n",
    "                    ss_ind = np.array([],dtype=int)\n",
    "                    for ind_i, desc in enumerate(all_ss_auto[:,2]):\n",
    "                        if (\"SS\" in desc) or (\"ss\" in desc):\n",
    "                            ss_ind = np.append(ss_ind, ind_i)\n",
    "                    all_ss_auto = all_ss_auto[ss_ind,:]\n",
    "\n",
    "                    ## get the array of after manual scanning\n",
    "                    all_ss_manu = np.loadtxt(manual_detection_filename, delimiter=\"\\t\",dtype='object')\n",
    "                    all_ss_manu = np.delete(all_ss_manu, np.where(all_ss_manu[:, 2] == \"Annotation\")[0], axis=0)\n",
    "                    all_ss_manu[:,[0,1]] = [np.double(x) for x in all_ss_manu[:,[0,1]]]\n",
    "                    ss_ind = np.array([],dtype=int)\n",
    "                    for ind_i, desc in enumerate(all_ss_manu[:,2]):\n",
    "                        if \"SS\" in desc:\n",
    "                            ss_ind = np.append(ss_ind, ind_i)\n",
    "                    all_ss_manu = all_ss_manu[ss_ind,:]\n",
    "\n",
    "                    ## compare to find rate od TP and FP\n",
    "                    TP = 0\n",
    "                    FP = 0\n",
    "                    for ss_auto in all_ss_auto:\n",
    "                        found = False\n",
    "                        for ss_manu in all_ss_manu:\n",
    "                            if overlap([ss_auto[0],ss_auto[0]+ss_auto[1]],[ss_manu[0],ss_manu[0]+ss_manu[1]]):\n",
    "                                TP +=1\n",
    "                                found = True\n",
    "                                break\n",
    "                        if found == False:\n",
    "                            FP +=1\n",
    "\n",
    "                    # FN = 0\n",
    "                    # for ss_manu in all_ss_manu:\n",
    "                    #     found = False\n",
    "                    #     for ss_auto in all_ss_auto:\n",
    "                    #         if overlap([ss_auto[0],ss_auto[0]+ss_auto[1]],[ss_manu[0],ss_manu[0]+ss_manu[1]]):\n",
    "                    #             found = True\n",
    "                    #             break\n",
    "                    #     if found == False:\n",
    "                    #         FN +=1\n",
    "\n",
    "                    Positive = np.shape(all_ss_manu)[0]   \n",
    "                    hitRate = TP/Positive\n",
    "                    #missRate = FN/Positive\n",
    "                    falseDiscoveryRate = FP/(FP+TP)\n",
    "                    \n",
    "                    comparison = [id,event_type, ver, Positive, TP, FP,hitRate, falseDiscoveryRate]\n",
    "                    all_comparisons.loc[len(all_comparisons)] = comparison\n",
    "\n",
    "    all_comparisons = all_comparisons.sort_values('minmax_ver')\n",
    "    all_comparisons = all_comparisons.sort_values('id')\n",
    "    return all_comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-פבר-23 12:20:35 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "24-פבר-23 12:21:39 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 8 1]\n",
      "sub:32_2, before exclude sleep stages:2861, after:1189\n",
      "sub:38_2, before exclude sleep stages:3715, after:2606\n",
      "sub:32_2, before filt:1189, after:405, after>1: after:284\n",
      "sub:38_2, before filt:2606, after:709, after>1: after:526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-פבר-23 12:22:51 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "24-פבר-23 12:23:55 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 8 1]\n",
      "sub:32_2, before exclude sleep stages:1982, after:788\n",
      "sub:38_2, before exclude sleep stages:2132, after:1490\n",
      "sub:32_2, before filt:788, after:290, after>1: after:181\n",
      "sub:38_2, before filt:1490, after:493, after>1: after:334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-פבר-23 12:25:00 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "24-פבר-23 12:26:01 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 8 1]\n",
      "sub:32_2, before exclude sleep stages:1056, after:413\n",
      "sub:38_2, before exclude sleep stages:1018, after:699\n",
      "sub:32_2, before filt:413, after:174, after>1: after:99\n",
      "sub:38_2, before filt:699, after:286, after>1: after:165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-פבר-23 12:27:05 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "24-פבר-23 12:28:16 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 9 1]\n",
      "sub:32_2, before exclude sleep stages:2925, after:1212\n",
      "sub:38_2, before exclude sleep stages:3748, after:2630\n",
      "sub:32_2, before filt:1212, after:404, after>1: after:286\n",
      "sub:38_2, before filt:2630, after:709, after>1: after:526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-פבר-23 12:29:30 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "24-פבר-23 12:30:33 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 9 1]\n",
      "sub:32_2, before exclude sleep stages:2063, after:815\n",
      "sub:38_2, before exclude sleep stages:2166, after:1514\n",
      "sub:32_2, before filt:815, after:289, after>1: after:185\n",
      "sub:38_2, before filt:1514, after:493, after>1: after:334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-פבר-23 12:31:40 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "24-פבר-23 12:32:42 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 9 1]\n",
      "sub:32_2, before exclude sleep stages:1139, after:440\n",
      "sub:38_2, before exclude sleep stages:1051, after:723\n",
      "sub:32_2, before filt:440, after:175, after>1: after:105\n",
      "sub:38_2, before filt:723, after:286, after>1: after:165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-פבר-23 12:33:46 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "24-פבר-23 12:34:51 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 10  1]\n",
      "sub:32_2, before exclude sleep stages:2952, after:1225\n",
      "sub:38_2, before exclude sleep stages:3761, after:2636\n",
      "sub:32_2, before filt:1225, after:404, after>1: after:287\n",
      "sub:38_2, before filt:2636, after:709, after>1: after:526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-פבר-23 12:36:04 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "24-פבר-23 12:37:08 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 10  1]\n",
      "sub:32_2, before exclude sleep stages:2095, after:830\n",
      "sub:38_2, before exclude sleep stages:2179, after:1520\n",
      "sub:32_2, before filt:830, after:291, after>1: after:186\n",
      "sub:38_2, before filt:1520, after:493, after>1: after:334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-פבר-23 12:38:17 | WARNING | Hypnogram is LONGER than data by 3.59 seconds. Cropping hypnogram to match data.size.\n",
      "24-פבר-23 12:39:17 | WARNING | Hypnogram is LONGER than data by 6.99 seconds. Cropping hypnogram to match data.size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 10  1]\n",
      "sub:32_2, before exclude sleep stages:1170, after:453\n",
      "sub:38_2, before exclude sleep stages:1066, after:729\n",
      "sub:32_2, before filt:453, after:177, after>1: after:106\n",
      "sub:38_2, before filt:729, after:286, after>1: after:167\n"
     ]
    }
   ],
   "source": [
    "## RUN THIS TO GET COMPARISONS OF SPINDLES MINMANX_SD OPTIONS\n",
    "run_comparison_of_spindle_minMax = True\n",
    "if(run_comparison_of_spindle_minMax):\n",
    "    testType = 0\n",
    "    if(testType==1):\n",
    "        file_ids = ['38_2']\n",
    "        minMax_sd_vers = [[4,10,1]]\n",
    "        electrodes_names_eventDetect = ['Fp2','F3']\n",
    "    elif(testType==2):\n",
    "        file_ids = ['32_2','38_2']\n",
    "        minMax_sd_vers = [[3,9,1],[4,10,1]]\n",
    "        electrodes_names_eventDetect = ['Fp2','F3']\n",
    "    elif(testType==3):\n",
    "        file_ids = ['32_2','38_2']\n",
    "        minMax_sd_vers = [[3,9,1],[4,10,1]]\n",
    "        electrodes_names_eventDetect = ['Fp1','Fp2','F3','F4','C3','C4','P3','P4','O1','O2']\n",
    "    else:\n",
    "        file_ids = ['32_2','38_2']\n",
    "        electrodes_names_eventDetect = ['Fp1','Fp2','F3','F4','C3','C4','P3','P4','O1','O2']\n",
    "        minMax_sd_vers = [[3,8,1],[4,8,1],[5,8,1],[3,9,1],[4,9,1],[5,9,1],[3,10,1],[4,10,1],[5,10,1]]\n",
    "        #file_ids = allsubsdata_perFile.keys()\n",
    "\n",
    "    with open(import_path, \"rb\") as file:\n",
    "        [allsubsdata_perFile, configu] = pickle.load(file)\n",
    "    fig_output_dir = f\"{configu['outputs_dir_path']}\\\\{output_dir_name}\"\n",
    "    if not os.path.exists(fig_output_dir): os.mkdir(fig_output_dir)\n",
    "\n",
    "    edfViewFormat_events_manual_dir = f'{fig_output_dir}\\\\EDFViewFormat_events'\n",
    "    edfViewFormat_events_output_dir = f'{fig_output_dir}\\\\EDFViewFormat_events\\\\minmax_sd_tests'\n",
    "    if os.path.exists(edfViewFormat_events_output_dir):\n",
    "        shutil.rmtree(edfViewFormat_events_output_dir)\n",
    "    os.mkdir(edfViewFormat_events_output_dir)\n",
    "\n",
    "    fig_output_dir = f\"{configu['outputs_dir_path']}\\\\{output_dir_name}\"\n",
    "    if not os.path.exists(fig_output_dir): os.mkdir(fig_output_dir)\n",
    "\n",
    "    for minMax_sd_ver in minMax_sd_vers:\n",
    "        with open(import_path, \"rb\") as file: [allsubsdata_perFile, configu] = pickle.load(file)\n",
    "        \n",
    "        all_electodes_ss_key = 'SS_AN'\n",
    "        minmax_sd_name = detect_ss_AndrillonNir(file_ids,minMax_sd_ver,all_electodes_ss_key,electrodes_names_eventDetect)\n",
    "        print(minmax_sd_name)\n",
    "\n",
    "        after_sleepStage_exclution_key = f\"{all_electodes_ss_key}_n2n3\"\n",
    "        filter_sleep_stages(file_ids,all_electodes_ss_key,after_sleepStage_exclution_key, [2.0,3.0]) \n",
    "\n",
    "        ss_key_to_use = after_sleepStage_exclution_key\n",
    "        multiElectdPerSS_text = \"multiElectd\"\n",
    "        singleElectdPerSS_text = \"singleElectd\"\n",
    "        multiElectdPerSS_key = f\"{ss_key_to_use}_{multiElectdPerSS_text}\"\n",
    "        singleElectdPerSS_key = f\"{ss_key_to_use}_{singleElectdPerSS_text}\"\n",
    "        group_spindles(ss_key_to_use,multiElectdPerSS_key, singleElectdPerSS_key)\n",
    "\n",
    "        edfviewFormatSuffix = 'efdViewFormat'\n",
    "        SS_multiElectdPerSS_efdViewFormat_key = f'{multiElectdPerSS_key}_{edfviewFormatSuffix}'\n",
    "        SS_singleElectdPerSS_efdViewFormat_key = f'{singleElectdPerSS_key}_{edfviewFormatSuffix}'\n",
    "        add_edfViewFormat_ss(file_ids,multiElectdPerSS_key,SS_multiElectdPerSS_efdViewFormat_key)\n",
    "        add_edfViewFormat_ss(file_ids,singleElectdPerSS_key,SS_singleElectdPerSS_efdViewFormat_key)\n",
    "\n",
    "        events_types_to_compare = [multiElectdPerSS_text,singleElectdPerSS_text]    \n",
    "        edfViewFormat_eventsTest_output_dir = f\"{edfViewFormat_events_output_dir}\\\\{minMax_sd_ver}\"\n",
    "        if os.path.exists(edfViewFormat_eventsTest_output_dir):  shutil.rmtree(edfViewFormat_eventsTest_output_dir)\n",
    "        os.mkdir(edfViewFormat_eventsTest_output_dir)\n",
    "        save_eventsSepratelyForComparison_edfViewFormat(file_ids,events_types_to_compare,edfViewFormat_eventsTest_output_dir)\n",
    "\n",
    "        scoring_edfViewFormat_key = f'scoring_{edfviewFormatSuffix}'\n",
    "        add_edfViewFormat_scoring(scoring_edfViewFormat_key)\n",
    "\n",
    "        events_types_to_save = ['scoring', multiElectdPerSS_text,singleElectdPerSS_text]    \n",
    "        save_eventsAllTogether_edfViewFormat(events_types_to_save,edfViewFormat_eventsTest_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>eventType</th>\n",
       "      <th>minmax_ver</th>\n",
       "      <th>Positive</th>\n",
       "      <th>TruePos</th>\n",
       "      <th>FalsePos</th>\n",
       "      <th>hitRate</th>\n",
       "      <th>falseDiscoveryRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[3, 8, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>136</td>\n",
       "      <td>148</td>\n",
       "      <td>0.855346</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[4, 9, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>114</td>\n",
       "      <td>71</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.383784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[4, 9, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>145</td>\n",
       "      <td>144</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.498270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[5, 8, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>102</td>\n",
       "      <td>72</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[4, 8, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[4, 8, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.386740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[5, 8, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>0.408805</td>\n",
       "      <td>0.343434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[5, 9, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>102</td>\n",
       "      <td>73</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.417143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[4, 10, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>145</td>\n",
       "      <td>146</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.501718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[3, 10, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>137</td>\n",
       "      <td>150</td>\n",
       "      <td>0.861635</td>\n",
       "      <td>0.522648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[3, 9, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>253</td>\n",
       "      <td>0.949686</td>\n",
       "      <td>0.626238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[3, 9, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>137</td>\n",
       "      <td>149</td>\n",
       "      <td>0.861635</td>\n",
       "      <td>0.520979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[5, 9, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>0.440252</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[5, 10, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>102</td>\n",
       "      <td>75</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.423729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[5, 10, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>71</td>\n",
       "      <td>35</td>\n",
       "      <td>0.446541</td>\n",
       "      <td>0.330189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[3, 8, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>254</td>\n",
       "      <td>0.949686</td>\n",
       "      <td>0.627160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[3, 10, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>253</td>\n",
       "      <td>0.949686</td>\n",
       "      <td>0.626238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[4, 10, 1]</td>\n",
       "      <td>159</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.381720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[5, 9, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>153</td>\n",
       "      <td>12</td>\n",
       "      <td>0.329741</td>\n",
       "      <td>0.072727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>38_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[5, 9, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>252</td>\n",
       "      <td>34</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>0.118881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[5, 8, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>252</td>\n",
       "      <td>34</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>0.118881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[5, 8, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>153</td>\n",
       "      <td>12</td>\n",
       "      <td>0.329741</td>\n",
       "      <td>0.072727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>38_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[4, 9, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>407</td>\n",
       "      <td>86</td>\n",
       "      <td>0.877155</td>\n",
       "      <td>0.174442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>38_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[4, 10, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>297</td>\n",
       "      <td>37</td>\n",
       "      <td>0.640086</td>\n",
       "      <td>0.110778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[4, 9, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>297</td>\n",
       "      <td>37</td>\n",
       "      <td>0.640086</td>\n",
       "      <td>0.110778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>38_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[5, 10, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>154</td>\n",
       "      <td>13</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.077844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[4, 8, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>297</td>\n",
       "      <td>37</td>\n",
       "      <td>0.640086</td>\n",
       "      <td>0.110778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[4, 8, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>407</td>\n",
       "      <td>86</td>\n",
       "      <td>0.877155</td>\n",
       "      <td>0.174442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>38_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[3, 10, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>430</td>\n",
       "      <td>279</td>\n",
       "      <td>0.926724</td>\n",
       "      <td>0.393512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>38_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[3, 10, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>389</td>\n",
       "      <td>137</td>\n",
       "      <td>0.838362</td>\n",
       "      <td>0.260456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>38_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[3, 9, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>389</td>\n",
       "      <td>137</td>\n",
       "      <td>0.838362</td>\n",
       "      <td>0.260456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[3, 9, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>430</td>\n",
       "      <td>279</td>\n",
       "      <td>0.926724</td>\n",
       "      <td>0.393512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38_2</td>\n",
       "      <td>multiElectd</td>\n",
       "      <td>[3, 8, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>389</td>\n",
       "      <td>137</td>\n",
       "      <td>0.838362</td>\n",
       "      <td>0.260456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[3, 8, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>430</td>\n",
       "      <td>279</td>\n",
       "      <td>0.926724</td>\n",
       "      <td>0.393512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>38_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[4, 10, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>407</td>\n",
       "      <td>86</td>\n",
       "      <td>0.877155</td>\n",
       "      <td>0.174442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>38_2</td>\n",
       "      <td>singleElectd</td>\n",
       "      <td>[5, 10, 1]</td>\n",
       "      <td>464</td>\n",
       "      <td>252</td>\n",
       "      <td>34</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>0.118881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     eventType  minmax_ver  Positive  TruePos  FalsePos   hitRate  \\\n",
       "0   32_2   multiElectd   [3, 8, 1]       159      136       148  0.855346   \n",
       "8   32_2   multiElectd   [4, 9, 1]       159      114        71  0.716981   \n",
       "9   32_2  singleElectd   [4, 9, 1]       159      145       144  0.911950   \n",
       "5   32_2  singleElectd   [5, 8, 1]       159      102        72  0.641509   \n",
       "3   32_2  singleElectd   [4, 8, 1]       159      145       145  0.911950   \n",
       "2   32_2   multiElectd   [4, 8, 1]       159      111        70  0.698113   \n",
       "4   32_2   multiElectd   [5, 8, 1]       159       65        34  0.408805   \n",
       "11  32_2  singleElectd   [5, 9, 1]       159      102        73  0.641509   \n",
       "15  32_2  singleElectd  [4, 10, 1]       159      145       146  0.911950   \n",
       "12  32_2   multiElectd  [3, 10, 1]       159      137       150  0.861635   \n",
       "7   32_2  singleElectd   [3, 9, 1]       159      151       253  0.949686   \n",
       "6   32_2   multiElectd   [3, 9, 1]       159      137       149  0.861635   \n",
       "10  32_2   multiElectd   [5, 9, 1]       159       70        35  0.440252   \n",
       "17  32_2  singleElectd  [5, 10, 1]       159      102        75  0.641509   \n",
       "16  32_2   multiElectd  [5, 10, 1]       159       71        35  0.446541   \n",
       "1   32_2  singleElectd   [3, 8, 1]       159      151       254  0.949686   \n",
       "13  32_2  singleElectd  [3, 10, 1]       159      151       253  0.949686   \n",
       "14  32_2   multiElectd  [4, 10, 1]       159      115        71  0.723270   \n",
       "28  38_2   multiElectd   [5, 9, 1]       464      153        12  0.329741   \n",
       "29  38_2  singleElectd   [5, 9, 1]       464      252        34  0.543103   \n",
       "23  38_2  singleElectd   [5, 8, 1]       464      252        34  0.543103   \n",
       "22  38_2   multiElectd   [5, 8, 1]       464      153        12  0.329741   \n",
       "27  38_2  singleElectd   [4, 9, 1]       464      407        86  0.877155   \n",
       "32  38_2   multiElectd  [4, 10, 1]       464      297        37  0.640086   \n",
       "26  38_2   multiElectd   [4, 9, 1]       464      297        37  0.640086   \n",
       "34  38_2   multiElectd  [5, 10, 1]       464      154        13  0.331897   \n",
       "20  38_2   multiElectd   [4, 8, 1]       464      297        37  0.640086   \n",
       "21  38_2  singleElectd   [4, 8, 1]       464      407        86  0.877155   \n",
       "31  38_2  singleElectd  [3, 10, 1]       464      430       279  0.926724   \n",
       "30  38_2   multiElectd  [3, 10, 1]       464      389       137  0.838362   \n",
       "24  38_2   multiElectd   [3, 9, 1]       464      389       137  0.838362   \n",
       "25  38_2  singleElectd   [3, 9, 1]       464      430       279  0.926724   \n",
       "18  38_2   multiElectd   [3, 8, 1]       464      389       137  0.838362   \n",
       "19  38_2  singleElectd   [3, 8, 1]       464      430       279  0.926724   \n",
       "33  38_2  singleElectd  [4, 10, 1]       464      407        86  0.877155   \n",
       "35  38_2  singleElectd  [5, 10, 1]       464      252        34  0.543103   \n",
       "\n",
       "    falseDiscoveryRate  \n",
       "0             0.521127  \n",
       "8             0.383784  \n",
       "9             0.498270  \n",
       "5             0.413793  \n",
       "3             0.500000  \n",
       "2             0.386740  \n",
       "4             0.343434  \n",
       "11            0.417143  \n",
       "15            0.501718  \n",
       "12            0.522648  \n",
       "7             0.626238  \n",
       "6             0.520979  \n",
       "10            0.333333  \n",
       "17            0.423729  \n",
       "16            0.330189  \n",
       "1             0.627160  \n",
       "13            0.626238  \n",
       "14            0.381720  \n",
       "28            0.072727  \n",
       "29            0.118881  \n",
       "23            0.118881  \n",
       "22            0.072727  \n",
       "27            0.174442  \n",
       "32            0.110778  \n",
       "26            0.110778  \n",
       "34            0.077844  \n",
       "20            0.110778  \n",
       "21            0.174442  \n",
       "31            0.393512  \n",
       "30            0.260456  \n",
       "24            0.260456  \n",
       "25            0.393512  \n",
       "18            0.260456  \n",
       "19            0.393512  \n",
       "33            0.174442  \n",
       "35            0.118881  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_comparison_of_spindle_minMax = True\n",
    "if(run_comparison_of_spindle_minMax):\n",
    "    events_types_to_compare = [multiElectdPerSS_text,singleElectdPerSS_text]\n",
    "    all_comp = preform_minmaxSD_comparison(events_types_to_compare,file_ids,minMax_sd_vers)\n",
    "    # all_comp.to_csv('ss_comparisons.csv',index=False)\n",
    "    display(all_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS TO GET scoring events file only\n",
    "run_scoring_eventFiles = True\n",
    "if(run_scoring_eventFiles):\n",
    "    testType = 1\n",
    "    if(testType==1):\n",
    "        with open(import_path, \"rb\") as file: [allsubsdata_perFile, configu] = pickle.load(file)\n",
    "        file_ids = allsubsdata_perFile.keys()\n",
    "        electrodes_names_eventDetect = ['Fp1','Fp2','F3','F4','C3','C4','P3','P4','O1','O2']\n",
    "\n",
    "\n",
    "    fig_output_dir = f\"{configu['outputs_dir_path']}\\\\{output_dir_name}\"\n",
    "    if not os.path.exists(fig_output_dir): os.mkdir(fig_output_dir)\n",
    "\n",
    "    edfViewFormat_events_manual_dir = f'{fig_output_dir}\\\\EDFViewFormat_events'\n",
    "    edfViewFormat_events_output_dir = f'{fig_output_dir}\\\\EDFViewFormat_events\\\\only_scoring'\n",
    "    if os.path.exists(edfViewFormat_events_output_dir):\n",
    "        shutil.rmtree(edfViewFormat_events_output_dir)\n",
    "    os.mkdir(edfViewFormat_events_output_dir)\n",
    "\n",
    "    all_electodes_sw_key = 'SW_AN'\n",
    "\n",
    "    edfviewFormatSuffix = 'efdViewFormat'\n",
    "\n",
    "    scoring_edfViewFormat_key = f'scoring_{edfviewFormatSuffix}'\n",
    "    add_edfViewFormat_scoring(scoring_edfViewFormat_key)\n",
    "\n",
    "    events_types_to_save = ['scoring']    \n",
    "    save_eventsAllTogether_edfViewFormat(events_types_to_save,edfViewFormat_events_output_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a change?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f544ce1a915a9875fad91c894e2c0bcad4b7a79945aa6027ef3ad27810072aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
