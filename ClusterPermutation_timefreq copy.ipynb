{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %reset\n",
    "# #%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.stats\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "import gc\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "from os.path import exists\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne import create_info\n",
    "#from auxiliary import AuxFuncs\n",
    "from IPython.utils import io\n",
    "\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs_dir = 'C:\\AnatArzData\\YKM_data\\epochs_and_evoked_allSubs'\n",
    "prepro_name = \"referenced\"\n",
    "import_type = \"5Electorodes_plainEEGLAB\"\n",
    "trial_exclution_str = \"_excOulierTrials-3.5\" #\"_excOulierTrials-2.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxFuncs:\n",
    "    def __init__(self, import_path):\n",
    "        # import epochs data and meta-data\n",
    "        with open(import_path, \"rb\") as file:\n",
    "            [allEvents_df, allEpochs_condIdDict, configu] = pickle.load(file)\n",
    "\n",
    "        self.allEpochs_condIdDict = allEpochs_condIdDict\n",
    "        self.allEvents_df = allEvents_df\n",
    "        self.config = configu\n",
    "        self.info, self.montage = self.get_subject_info()\n",
    "\n",
    "    def get_subject_info(self, example_subject=\"32\"):\n",
    "        subject_setfile_wake_n = f'{self.config[\"set_files_dir\"]}\\\\s_{example_subject}_wake_night_referenced.set'\n",
    "        output_file_path = (\n",
    "            f\"{self.config['outputs_dir_path'] }/epochs_Wn_s{example_subject}_file\"\n",
    "        )\n",
    "\n",
    "        if exists(output_file_path):\n",
    "            with open(output_file_path, \"rb\") as config_dictionary_file:\n",
    "                epochs_Wn_example_sub = pickle.load(config_dictionary_file)\n",
    "                # print(epochs_Wn_example_sub)\n",
    "        else:\n",
    "            epochs_Wn_example_sub = mne.io.read_epochs_eeglab(\n",
    "                subject_setfile_wake_n,\n",
    "                events=None,\n",
    "                event_id=None,\n",
    "                eog=(),\n",
    "                verbose=None,\n",
    "                uint16_codec=None,\n",
    "            )\n",
    "            with open(output_file_path, \"wb\") as epochs_Wn_s_example_file:\n",
    "                pickle.dump(epochs_Wn_example_sub, epochs_Wn_s_example_file)\n",
    "\n",
    "        montage = mne.channels.make_standard_montage(\"GSN-HydroCel-128\")\n",
    "        epochs_Wn_example_sub_piked = epochs_Wn_example_sub.pick_channels(\n",
    "            self.config[\"ch_names\"]\n",
    "        )\n",
    "        epochs_Wn_example_sub_monatged = epochs_Wn_example_sub_piked.set_montage(\n",
    "            montage\n",
    "        )\n",
    "        epochs_info = epochs_Wn_example_sub_monatged.info\n",
    "        return epochs_info, epochs_Wn_example_sub_monatged\n",
    "\n",
    "    def getEpochsPerCond(self, cond_df, y_ax, dataset, outputType=\"dict\"):\n",
    "        df_minTrials = copy.deepcopy(cond_df)\n",
    "        df_minTrials = df_minTrials[\n",
    "            (df_minTrials.SamplesCount > 0)\n",
    "        ]  # discard cond with 0 enough samples\n",
    "        keys = (str(key) for key in df_minTrials.Cond_id)\n",
    "        epochs_allSamples = {str_key: dataset[str_key] for str_key in keys}\n",
    "        if outputType == \"array\":\n",
    "            epochs_allSamples_arr = np.zeros(\n",
    "                (len(self.config[\"electrodes\"]), len(y_ax), 0)\n",
    "            )\n",
    "            for epoch_key in epochs_allSamples:\n",
    "                epochs_allSamples_arr = np.concatenate(\n",
    "                    (epochs_allSamples_arr, epochs_allSamples[epoch_key]), axis=2\n",
    "                )\n",
    "            return df_minTrials, epochs_allSamples_arr\n",
    "        return df_minTrials, epochs_allSamples\n",
    "\n",
    "    # output: [#epochs, #elect, #times]\n",
    "    def getEpochsPerConstraint(self, constraints):\n",
    "        curr_df = self.allEvents_df.copy(deep=True)\n",
    "        # apply constraints\n",
    "        for key in constraints:\n",
    "            curr_df = curr_df[(curr_df[key] == constraints[key])]\n",
    "\n",
    "        curr_df = curr_df[\n",
    "            (curr_df.SamplesCount > 0)\n",
    "        ]  # discard cond with 0 enough samples\n",
    "        epochsPerCond = {}\n",
    "        for key in curr_df.Cond_id:\n",
    "            epochsPerCond[str(key)] = self.allEpochs_condIdDict[str(key)]\n",
    "\n",
    "        # load the metadata first and them the data. More time efficient\n",
    "        epochs_name_in_const = []\n",
    "        epochs_trial_num_per_cond = []\n",
    "        for cond in epochsPerCond:\n",
    "            for curr_cond_trial in range(epochsPerCond[cond].shape[2]):\n",
    "                if len(epochs_name_in_const) == 0:\n",
    "                    epochs_name_in_const = [cond]\n",
    "                    epochs_trial_num_per_cond = [curr_cond_trial]\n",
    "                else:\n",
    "                    epochs_name_in_const = np.append(epochs_name_in_const, cond)\n",
    "                    epochs_trial_num_per_cond = np.append(\n",
    "                        epochs_trial_num_per_cond, curr_cond_trial\n",
    "                    )\n",
    "\n",
    "        epochs_in_const = np.zeros(\n",
    "            (\n",
    "                len(epochs_name_in_const),\n",
    "                len(self.config[\"electrodes\"]),\n",
    "                len(self.config[\"times\"]),\n",
    "            )\n",
    "        )\n",
    "        trial = 0\n",
    "        for cond in epochsPerCond:\n",
    "            for curr_cond_trial in range(epochsPerCond[cond].shape[2]):\n",
    "                epochs_in_const[trial, :, :] = epochsPerCond[cond][\n",
    "                    :, :, curr_cond_trial\n",
    "                ]\n",
    "                trial += 1\n",
    "\n",
    "        return epochs_in_const, epochs_name_in_const, epochs_trial_num_per_cond\n",
    "\n",
    "    # output: [#conds, #elect, #times]\n",
    "    def getEvokedPerCondAndElectd(\n",
    "        self,\n",
    "        constraints,\n",
    "        df,\n",
    "        dataset,\n",
    "        y_ax,\n",
    "        outputType=\"array\",\n",
    "        tmin=-0.1,\n",
    "        baseline=(None, 0),\n",
    "    ):\n",
    "        curr_df = copy.deepcopy(df)\n",
    "        # apply constraints\n",
    "        for key in constraints:\n",
    "            curr_df = curr_df[curr_df[key] == constraints[key]]\n",
    "\n",
    "        conds_df, epochsPerCond = self.getEpochsPerCond(curr_df, y_ax, dataset)\n",
    "        evoked_perCond_andElectd = np.zeros(\n",
    "            (len(epochsPerCond), np.size(self.config[\"electrodes\"]), np.size(y_ax))\n",
    "        )\n",
    "\n",
    "        for cond_i, cond in enumerate(epochsPerCond):\n",
    "            evoked_perCond_andElectd[cond_i] = np.squeeze(\n",
    "                np.nanmean(epochsPerCond[cond], axis=2)\n",
    "            )\n",
    "\n",
    "        if outputType == \"array\":\n",
    "            return conds_df, evoked_perCond_andElectd\n",
    "        if outputType == \"mne\":\n",
    "            mne_epochs = mne.EpochsArray(\n",
    "                evoked_perCond_andElectd, self.info, tmin=tmin, baseline=baseline\n",
    "            )\n",
    "            return conds_df, mne_epochs\n",
    "\n",
    "    def create_output_dir(self, dir_name):\n",
    "        fig_output_dir_path = f\"{self.config['outputs_dir_path']}/{dir_name}\"\n",
    "        if not exists(fig_output_dir_path):\n",
    "            mkdir(fig_output_dir_path)\n",
    "        return fig_output_dir_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import_path = f'{epochs_dir}\\\\{import_type}{trial_exclution_str}.pkl'\n",
    "aux = AuxFuncs(import_path)\n",
    "\n",
    "allEpochs_perCond = aux.allEpochs_condIdDict\n",
    "allEvents_df = aux.allEvents_df\n",
    "c = aux.config\n",
    "times = c['times']\n",
    "time0_i = c['time0_i']\n",
    "\n",
    "fig_output_dir = f\"{c['outputs_dir_path']}/timefreq_clusterPerm\"\n",
    "if not os.path.exists(fig_output_dir):\n",
    "    os.mkdir(fig_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def applyDesign(ax,title=''):\n",
    "    ax.get_figure().patch.set_facecolor('#f5f1ecff')\n",
    "    ax.set_facecolor('silver')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc = 'upper right',prop={'size': 10})\n",
    "    ax.axvline(x=0,color='gray', linestyle='--',label =\"_nolegend_\")\n",
    "    ax.axhline(y=0, color='gray', linestyle='-',label =\"_nolegend_\")\n",
    "    ax.set_ylabel('magnitude')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax.set_xlabel('msec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Time-freq functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cond_1 = {'TOA_cond':'Rand','Vigilance':'N3'}\n",
    "cond_2 = {'TOA_cond':'Fixed','Vigilance':'N3'}\n",
    "contrast_name = \"allSubs_RandvsFixed_N3\"\n",
    "\n",
    "# Parameters:\n",
    "# ==================\n",
    "# zscore baseline\n",
    "# Tail is 0, so the statistic is thresholded on both sides of the distribution.\n",
    "baseline_period = (None, 0) ## For timefreq analysis\n",
    "p_value = 0.05 # default 0.05 # for clusters\n",
    "decim = 1# default 2 for testing.. For reals- 1\n",
    "n_permutations=1000 # default 1k for testing. For reals - 10K\n",
    "min_freq = 4\n",
    "freqs = np.arange(min_freq,80, 1)  # define frequencies of interest\n",
    "n_cycles = freqs / min_freq # different number of cycle per frequency\n",
    "\n",
    "tail = 0 # 0 = two-tailed test (for clusters (as we want positive and negative clusters))\n",
    "p_value_pixels = 0.05\n",
    "\n",
    "test_per_voxel='ttest'\n",
    "is_tfr_performAverageBaseline=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.zeros((len(c['electrodes']), len(freqs),len(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_clusters_map(ax1,T_obs,ch_idx,tfr_epochs,t_thresh,T_obs_plot):\n",
    "    vmax = np.max(np.abs(T_obs))\n",
    "    vmin = -vmax\n",
    "    ax1.imshow(T_obs[ch_idx], cmap=plt.cm.gray,\n",
    "               extent=[times[0], times[-1], freqs[0], freqs[-1]],\n",
    "               aspect='auto', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax1.imshow(T_obs_plot[ch_idx], cmap=plt.cm.RdBu_r,\n",
    "               extent=[times[0], times[-1], freqs[0], freqs[-1]],\n",
    "               aspect='auto', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    #ax1.set_colorbar()\n",
    "    ax1.set_xlabel('Time (ms)')\n",
    "    ax1.set_ylabel('Frequency (Hz)')\n",
    "    ax1.set_title(f'Induced power ({tfr_epochs.ch_names[ch_idx]})\\nThreshold:{t_thresh}\\ncluster p_val={p_value},n_permutation={n_permutations}\\ncontrast:{cond_1};{cond_2}')\n",
    "def plot_elecds_erps(ax2,mean_epochs_time_diff,ch_idx,tfr_epochs):\n",
    "    ax2.plot(times,mean_epochs_time_diff.T,color='blue')\n",
    "    mean_electrods = np.nanmean(mean_epochs_time_diff,axis=0)\n",
    "    ax2.plot(times,mean_electrods,color='yellow',label='mean')\n",
    "    ax2.plot(times,mean_epochs_time_diff[ch_idx,:],label=tfr_epochs.ch_names[ch_idx],color='red')\n",
    "    ax2.legend()\n",
    "    ax2.set_xlim(times[0],times[-1])\n",
    "    applyDesign(ax2,'ERP difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run many contrasts at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now computeing {'TOA_cond': 'Rand', 'Vigilance': 'Wn'} and {'TOA_cond': 'Fixed', 'Vigilance': 'Wn'}\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "36 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "32 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "34 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "36 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "32 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "34 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "32 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "35 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "35 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "35 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "34 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "34 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "35 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "34 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "34 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "36 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "35 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "32 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "35 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "9 matching events found\n",
      "Setting baseline interval to [-0.1, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 5\n",
      "stat_fun(H1): min=-1.834196 max=2.575584\n",
      "Running initial clustering …\n",
      "Found 3 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| Permuting : 999/999 [00:06<00:00,  162.83it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 115\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNow computeing \u001b[39m\u001b[39m{\u001b[39;00mcond_1\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mcond_2\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    114\u001b[0m contrast_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcontrast\u001b[39m.\u001b[39mtitle()\u001b[39m}\u001b[39;00m\u001b[39m_-\u001b[39m\u001b[39m{\u001b[39;00mtest_per_voxel\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 115\u001b[0m getClustersPerConditions_5timesBaseline(c,cond_1, cond_2, contrast_name,cluster_range_index\u001b[39m=\u001b[39;49m[time0_i, time0_i\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m],is_tfr_performAverageBaseline\u001b[39m=\u001b[39;49mis_tfr_performAverageBaseline, test_per_voxel\u001b[39m=\u001b[39;49mtest_per_voxel)\n",
      "Cell \u001b[1;32mIn [20], line 93\u001b[0m, in \u001b[0;36mgetClustersPerConditions_5timesBaseline\u001b[1;34m(c, cond_1, cond_2, contrast_name, cluster_range_index, is_tfr_performAverageBaseline, baseline_period, test_per_voxel)\u001b[0m\n\u001b[0;32m     90\u001b[0m         T_obs_plot[c] \u001b[39m=\u001b[39m T_obs[c]\n\u001b[0;32m     91\u001b[0m mean_epochs_time_diff \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmean(epochs_time_diff,axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m padded_t_obs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(c[\u001b[39m'\u001b[39;49m\u001b[39melectrodes\u001b[39;49m\u001b[39m'\u001b[39;49m]), \u001b[39mlen\u001b[39m(freqs),\u001b[39mlen\u001b[39m(times)))\n\u001b[0;32m     94\u001b[0m padded_t_obs_plot \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(c[\u001b[39m'\u001b[39m\u001b[39melectrodes\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mlen\u001b[39m(freqs),\u001b[39mlen\u001b[39m(times)))\n\u001b[0;32m     95\u001b[0m padded_t_obs[:,:,cluster_range_index[\u001b[39m0\u001b[39m]:cluster_range_index[\u001b[39m1\u001b[39m]]\u001b[39m=\u001b[39mT_obs\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "def stat_fun_wilcox(X):\n",
    "    result = scipy.stats.wilcoxon(X)\n",
    "    return result.statistic\n",
    "\n",
    "def getClustersPerConditions_5timesBaseline(c,cond_1,cond_2, contrast_name,cluster_range_index,is_tfr_performAverageBaseline=True,baseline_period=(None, 0),test_per_voxel='ttest'):\n",
    "    if test_per_voxel=='ttest':\n",
    "        test_per_voxel = mne.stats.ttest_1samp_no_p\n",
    "    else:\n",
    "        test_per_voxel = stat_fun_wilcox\n",
    "\n",
    "    epochs_time_diff = []\n",
    "    epochs_power_diff = []\n",
    "    for sub in c['subs']:\n",
    "        currContr_conds1 = cond_1.copy()\n",
    "        currContr_conds1['Subject'] = sub\n",
    "        __, cont_epochs1 = aux.getEvokedPerCondAndElectd(currContr_conds1,allEvents_df,allEpochs_perCond,times, outputType='mne')\n",
    "\n",
    "        if cond_2 == \"baseline\":\n",
    "            baseline_epochs_data = copy.deepcopy(cont_epochs1.get_data())\n",
    "\n",
    "            baseline_orig_data = baseline_epochs_data[:,:,0:time0_i]\n",
    "            baseline_epochs_data[:,:,time0_i:time0_i*2] = baseline_orig_data\n",
    "            baseline_epochs_data[:,:,time0_i*2:time0_i*3] = baseline_orig_data\n",
    "            baseline_epochs_data[:,:,time0_i*3:time0_i*4] = baseline_orig_data\n",
    "            baseline_epochs_data[:,:,time0_i*4:time0_i*5] = baseline_orig_data\n",
    "            baseline_epochs_data[:,:,time0_i*5:] = baseline_orig_data[:,:,:13]\n",
    "\n",
    "            with io.capture_output() as captured: # suppress output\n",
    "                cont_epochs2 = mne.EpochsArray(baseline_epochs_data, aux.info,tmin=-0.1)\n",
    "        else:\n",
    "            currContr_conds2 = cond_2.copy()\n",
    "            currContr_conds2['Subject'] = sub\n",
    "            __, cont_epochs2 = aux.getEvokedPerCondAndElectd(currContr_conds2,allEvents_df,allEpochs_perCond,times, outputType='mne')\n",
    "\n",
    "        if is_tfr_performAverageBaseline:\n",
    "            with io.capture_output() as captured: # suppress output\n",
    "                tfr_epochs1 = tfr_morlet(cont_epochs1, freqs, n_cycles=n_cycles, decim=decim, average=False, return_itc=False)\n",
    "                tfr_epochs2 = tfr_morlet(cont_epochs2, freqs, n_cycles=n_cycles, decim=decim, average=False, return_itc=False)\n",
    "\n",
    "            both_tfr_data = np.concatenate((tfr_epochs1.data,tfr_epochs2.data),axis=0)\n",
    "            both_tfr_data_tfr = copy.deepcopy(tfr_epochs1)\n",
    "            both_tfr_data_tfr.data = both_tfr_data\n",
    "\n",
    "            #Correction is applied to all epoch and channel together in the following way: 1.Calculate the mean signal of the baseline period. 2.Subtract this mean from the entire epoch.\n",
    "            with io.capture_output() as captured: # suppress output\n",
    "                both_tfr_data_tfr.apply_baseline(mode='zscore', baseline=baseline_period)\n",
    "\n",
    "            num_of_cond1_trials = tfr_epochs1.data.shape[0]\n",
    "            epochs_power1 = np.mean(both_tfr_data_tfr.data[:num_of_cond1_trials,:,:,:],axis=(0,1)) # elec, freqs, time\n",
    "            epochs_power2 = np.mean(both_tfr_data_tfr.data[num_of_cond1_trials:,:,:,:],axis=(0,1)) # elec, freqs, time\n",
    "\n",
    "            epochs_time_diff.append(np.mean(cont_epochs1,axis=0) - np.mean(cont_epochs2,axis=0))\n",
    "        else: # apply baseline seperately\n",
    "            tfr_epochs1 = tfr_morlet(cont_epochs1, freqs, n_cycles=n_cycles, decim=decim, average=True, return_itc=False)\n",
    "            tfr_epochs2 = tfr_morlet(cont_epochs2, freqs, n_cycles=n_cycles, decim=decim, average=True, return_itc=False)\n",
    "            tfr_epochs1.apply_baseline(mode='zscore', baseline=baseline_period)\n",
    "            tfr_epochs2.apply_baseline(mode='zscore', baseline=baseline_period)\n",
    "            epochs_power1 = tfr_epochs1.data # elec, freqs, time\n",
    "            epochs_power2 = tfr_epochs2.data # elec, freqs, time\n",
    "\n",
    "            epochs_time_diff.append(np.mean(cont_epochs1.get_data(),axis=0) - np.mean(cont_epochs2.get_data(),axis=0))\n",
    "\n",
    "        means_diff = epochs_power1-epochs_power2\n",
    "        epochs_power_diff.append(means_diff)\n",
    "\n",
    "    # (n_epochs, n_channels, n_freqs, n_times)\n",
    "    epochs_power_diff_arr = np.zeros((len(c['subs']),len(c['electrodes']),len(freqs),len(times)))\n",
    "    for s,subject in enumerate(c['subs']):\n",
    "        epochs_power_diff_arr[s,:,:,:] = epochs_power_diff[s]\n",
    "\n",
    "    #### Define adjacency for statistics\n",
    "    tfr_epochs = tfr_epochs1\n",
    "    sensor_adjacency, ch_names = mne.channels.find_ch_adjacency(tfr_epochs.info,ch_type=None)\n",
    "    use_idx = [ch_names.index(ch_name) for ch_name in tfr_epochs.ch_names]\n",
    "    sensor_adjacency = sensor_adjacency[use_idx][:, use_idx]\n",
    "    assert sensor_adjacency.shape == (len(tfr_epochs.ch_names), len(tfr_epochs.ch_names))\n",
    "    assert epochs_power_diff_arr.shape == (len(c['subs']), len(tfr_epochs.ch_names), len(tfr_epochs.freqs), len(tfr_epochs.times))\n",
    "    adjacency = mne.stats.combine_adjacency(sensor_adjacency, len(tfr_epochs.freqs), len(tfr_epochs.times))\n",
    "    assert adjacency.shape[0] == adjacency.shape[1] == len(tfr_epochs.ch_names) * len(tfr_epochs.freqs) * len(tfr_epochs.times)\n",
    "\n",
    "    ### run cluster permutation\n",
    "    degrees_of_freedom = len(c['subs']) - 1\n",
    "    t_thresh = scipy.stats.t.ppf(1 - p_value_pixels / 2, df=degrees_of_freedom)\n",
    "    T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(epochs_power_diff_arr[...,cluster_range_index[0]:cluster_range_index[1]], n_permutations=n_permutations, threshold=t_thresh, tail=tail,  out_type='mask', verbose=True, stat_fun=test_per_voxel)\n",
    "\n",
    "    ############# plot\n",
    "    T_obs_plot = np.nan * np.ones_like(T_obs)\n",
    "    for c, clust_p_val in zip(clusters, cluster_p_values):\n",
    "        if clust_p_val <= p_value:\n",
    "            T_obs_plot[c] = T_obs[c]\n",
    "    mean_epochs_time_diff = np.nanmean(epochs_time_diff,axis=0)\n",
    "\n",
    "    padded_t_obs = np.zeros((len(c['electrodes']), len(freqs),len(times)))\n",
    "    padded_t_obs_plot = np.zeros((len(c['electrodes']), len(freqs),len(times)))\n",
    "    padded_t_obs[:,:,cluster_range_index[0]:cluster_range_index[1]]=T_obs\n",
    "    padded_t_obs_plot[:,:,cluster_range_index[0]:cluster_range_index[1]]=T_obs_plot\n",
    "\n",
    "    for ch_idx, elecd in enumerate(c['electrodes']):\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "        fig.subplots_adjust(left=0.12,bottom= 0.08,right= 0.96, top=0.85, wspace=0.2, hspace=0.3)\n",
    "        plot_clusters_map(ax1,padded_t_obs,ch_idx,tfr_epochs,t_thresh,padded_t_obs_plot)\n",
    "        plot_elecds_erps(ax2,mean_epochs_time_diff,ch_idx,tfr_epochs)\n",
    "        plt.ioff()\n",
    "        plt.savefig(f'{fig_output_dir}/timeFreq_clusters_{contrast_name}_{tfr_epochs.ch_names[ch_idx]}.png',bbox_inches='tight')\n",
    "       \n",
    "       \n",
    "contrasts_5timesBase = {}    \n",
    "contrasts_5timesBase[\"allSubs_RandvsFixed_Wn\"] = {'cond_1':{'TOA_cond':'Rand','Vigilance':'Wn'},'cond_2':{'TOA_cond':'Fixed','Vigilance':'Wn'}}\n",
    "for contrast in contrasts_5timesBase:\n",
    "    cond_1 = contrasts_5timesBase[contrast]['cond_1']\n",
    "    cond_2 = contrasts_5timesBase[contrast]['cond_2']\n",
    "    print(f'Now computeing {cond_1} and {cond_2}')\n",
    "\n",
    "    contrast_name = f\"{contrast.title()}_-{test_per_voxel}\"\n",
    "    getClustersPerConditions_5timesBaseline(c,cond_1, cond_2, contrast_name,cluster_range_index=[time0_i, time0_i*2],is_tfr_performAverageBaseline=is_tfr_performAverageBaseline, test_per_voxel=test_per_voxel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((len(c['electrodes']), len(freqs),len(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9727a610775b7f1eee3acb3e384f6b4e37636c36178c83f8f41bf15b00c05101"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
